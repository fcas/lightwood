

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Using your own pre-processing methods in Lightwood &mdash; lightwood 22.12.1.0 documentation</title>
  

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/graphviz.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: white" >
          

          
            <a href="../../index.html">
          

          
            
            <img src="../../_static/mindsdblogo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                22.12.1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Tutorials</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">API</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../data.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Data</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../encoder.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Encoders</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mixer.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Mixers</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ensemble.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Ensemble</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../analysis.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Analysis</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../helpers.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Helpers</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../lightwood_philosophy.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Lightwood</span> <span class="pre">Philosophy</span></code></a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">lightwood</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Using your own pre-processing methods in Lightwood</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../_sources/tutorials/custom_cleaner/custom_cleaner.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars and line breaks on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
    white-space: pre;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
.jp-RenderedHTMLCommon table,
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.jp-RenderedHTMLCommon thead,
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.jp-RenderedHTMLCommon tr,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon td,
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.jp-RenderedHTMLCommon th,
div.rendered_html th {
  font-weight: bold;
}
.jp-RenderedHTMLCommon tbody tr:nth-child(odd),
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.jp-RenderedHTMLCommon tbody tr:hover,
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Using-your-own-pre-processing-methods-in-Lightwood">
<h1>Using your own pre-processing methods in Lightwood<a class="headerlink" href="#Using-your-own-pre-processing-methods-in-Lightwood" title="Permalink to this headline">¶</a></h1>
<div class="section" id="Date:-2021.10.07">
<h2>Date: 2021.10.07<a class="headerlink" href="#Date:-2021.10.07" title="Permalink to this headline">¶</a></h2>
<p>For the notebook below, we’ll be exploring how to make <strong>custom pre-processing</strong> methods for our data. Lightwood has standard cleaning protocols to handle a variety of different data types, however, we want users to feel comfortable augmenting and addressing their own changes. To do so, we’ll highlight the approach we would take below:</p>
<p>We will use data from <a class="reference external" href="https://www.kaggle.com/c/commonlitreadabilityprize/data?select=train.csv">Kaggle</a>.</p>
<p>The data has several columns, but ultimately aims to use text to predict a <em>readability score</em>. There are also some columns that I do not want to use when making predictions, such as <code class="docutils literal notranslate"><span class="pre">url_legal</span></code>, <code class="docutils literal notranslate"><span class="pre">license</span></code>, among others.</p>
<p>In this tutorial, we’re going to focus on making changes to 2 columns: (1) <strong>excerpt</strong>, a text column, and ensuring we remove stop words using NLTK. (2) <strong>target</strong>, the goal to predict; we will make this explicitly non-negative.</p>
<p>Note, for this ACTUAL challenge, negative and positive are meaningful. We are using this as an example dataset to demonstrate how you can make changes to your underlying dataset and proceed to building powerful predictors.</p>
<p>Let’s get started!</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import numpy as np
import pandas as pd
import torch
import nltk

import os
import sys

# Lightwood modules
import lightwood as lw
from lightwood import ProblemDefinition, \
                      JsonAI, \
                      json_ai_from_problem, \
                      code_from_json_ai, \
                      predictor_from_code
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
<span class="ansi-green-fg">INFO:lightwood-2356:No torchvision detected, image helpers not supported.</span>
<span class="ansi-green-fg">INFO:lightwood-2356:No torchvision/pillow detected, image encoder not supported</span>
/opt/hostedtoolcache/Python/3.9.15/x64/lib/python3.9/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.15/x64/lib/python3.9/site-packages/gluonts/model/deepar/__init__.py:18: FutureWarning: The module gluonts.model.deepar has been moved to gluonts.mx.model.deepar. In GluonTS v0.12 it will be no longer possible to use the old path. Try to use &#39;from gluonts.mx import DeepAREstimator&#39;.
  warnings.warn(
</pre></div></div>
</div>
<div class="section" id="1)-Load-your-data">
<h3>1) Load your data<a class="headerlink" href="#1)-Load-your-data" title="Permalink to this headline">¶</a></h3>
<p>Lightwood uses <code class="docutils literal notranslate"><span class="pre">pandas</span></code> in order to handle datasets, as this is a very standard package in datascience. We can load our dataset using pandas in the following manner (make sure your data is in the data folder!)</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Load the data
data = pd.read_csv(&quot;https://mindsdb-example-data.s3.eu-west-2.amazonaws.com/jupyter/train.csv.zip&quot;)
data.head()
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>url_legal</th>
      <th>license</th>
      <th>excerpt</th>
      <th>target</th>
      <th>standard_error</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>c12129c31</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>When the young people returned to the ballroom...</td>
      <td>-0.340259</td>
      <td>0.464009</td>
    </tr>
    <tr>
      <th>1</th>
      <td>85aa80a4c</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>All through dinner time, Mrs. Fayre was somewh...</td>
      <td>-0.315372</td>
      <td>0.480805</td>
    </tr>
    <tr>
      <th>2</th>
      <td>b69ac6792</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>As Roger had predicted, the snow departed as q...</td>
      <td>-0.580118</td>
      <td>0.476676</td>
    </tr>
    <tr>
      <th>3</th>
      <td>dd1000b26</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>And outside before the palace a great garden w...</td>
      <td>-1.054013</td>
      <td>0.450007</td>
    </tr>
    <tr>
      <th>4</th>
      <td>37c1b32fb</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Once upon a time there were Three Bears who li...</td>
      <td>0.247197</td>
      <td>0.510845</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>We see <strong>6 columns</strong>, a variety which are numerical, missing numbers, text, and identifiers or “ids”. For our predictive task, we are only interested in 2 such columns, the <strong>excerpt</strong> and <strong>target</strong> columns.</p>
</div>
<div class="section" id="2)-Create-a-JSON-AI-default-object">
<h3>2) Create a JSON-AI default object<a class="headerlink" href="#2)-Create-a-JSON-AI-default-object" title="Permalink to this headline">¶</a></h3>
<p>Before we create a custom cleaner object, let’s first create JSON-AI syntax for our problem based on its specifications. We can do so by setting up a <code class="docutils literal notranslate"><span class="pre">ProblemDefinition</span></code>. The <code class="docutils literal notranslate"><span class="pre">ProblemDefinition</span></code> allows us to specify the target, the column we intend to predict, along with other details.</p>
<p>The end goal of JSON-AI is to provide <em>a set of instructions on how to compile a machine learning pipeline</em>.</p>
<p>In this case, let’s specify our target, the aptly named <strong>target</strong> column. We will also tell JSON-AI to throw away features we never intend to use, such as “url_legal”, “license”, and “standard_error”. We can do so in the following lines:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Setup the problem definition
problem_definition = {
    &#39;target&#39;: &#39;target&#39;,
    &quot;ignore_features&quot;: [&quot;url_legal&quot;, &quot;license&quot;, &quot;standard_error&quot;]
}

# Generate the j{ai}son syntax
json_ai = json_ai_from_problem(data, problem_definition)
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
<span class="ansi-green-fg">INFO:lightwood-2356:Dropping features: [&#39;url_legal&#39;, &#39;license&#39;, &#39;standard_error&#39;]</span>
<span class="ansi-green-fg">INFO:type_infer-2356:Analyzing a sample of 2478</span>
<span class="ansi-green-fg">INFO:type_infer-2356:from a total population of 2834, this is equivalent to 87.4% of your data.</span>
<span class="ansi-green-fg">INFO:type_infer-2356:Infering type for: id</span>
<span class="ansi-green-fg">INFO:type_infer-2356:Doing text detection for column: id</span>
<span class="ansi-green-fg">INFO:type_infer-2356:Column id has data type categorical</span>
<span class="ansi-green-fg">INFO:type_infer-2356:Infering type for: excerpt</span>
<span class="ansi-green-fg">INFO:type_infer-2356:Doing text detection for column: excerpt</span>
<span class="ansi-green-fg">INFO:type_infer-2356:Infering type for: target</span>
<span class="ansi-green-fg">INFO:type_infer-2356:Column target has data type float</span>
<span class="ansi-yellow-fg">WARNING:type_infer-2356:Column id is an identifier of type &#34;Hash-like identifier&#34;</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2356:Starting statistical analysis</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2356:Dropping features: [&#39;id&#39;]</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2356:Finished statistical analysis</span>
</pre></div></div>
</div>
<p>Lightwood, as it processes the data, will provide the user a few pieces of information.</p>
<ol class="arabic simple">
<li><p>It drops the features we specify in the <code class="docutils literal notranslate"><span class="pre">ignore_features</span></code> argument</p></li>
<li><p>It takes a small sample of data from each column to <em>automatically infer the data type</em></p></li>
<li><p>For each column that was not ignored, it identifies the most likely data type.</p></li>
<li><p>It notices that “ID” is a hash-like-identifier.</p></li>
<li><p>It conducts a small statistical analysis on the distributions in order to generate syntax.</p></li>
</ol>
<p>As soon as you request a JSON-AI object, Lightwood automatically creates functional syntax from your data. You can see it as follows:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>print(json_ai.to_json())
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{
    &#34;encoders&#34;: {
        &#34;target&#34;: {
            &#34;module&#34;: &#34;NumericEncoder&#34;,
            &#34;args&#34;: {
                &#34;is_target&#34;: &#34;True&#34;,
                &#34;positive_domain&#34;: &#34;$statistical_analysis.positive_domain&#34;
            }
        },
        &#34;excerpt&#34;: {
            &#34;module&#34;: &#34;PretrainedLangEncoder&#34;,
            &#34;args&#34;: {
                &#34;output_type&#34;: &#34;$dtype_dict[$target]&#34;,
                &#34;stop_after&#34;: &#34;$problem_definition.seconds_per_encoder&#34;
            }
        }
    },
    &#34;dtype_dict&#34;: {
        &#34;excerpt&#34;: &#34;rich_text&#34;,
        &#34;target&#34;: &#34;float&#34;
    },
    &#34;dependency_dict&#34;: {},
    &#34;model&#34;: {
        &#34;module&#34;: &#34;BestOf&#34;,
        &#34;args&#34;: {
            &#34;submodels&#34;: [
                {
                    &#34;module&#34;: &#34;Neural&#34;,
                    &#34;args&#34;: {
                        &#34;fit_on_dev&#34;: true,
                        &#34;stop_after&#34;: &#34;$problem_definition.seconds_per_mixer&#34;,
                        &#34;search_hyperparameters&#34;: true
                    }
                },
                {
                    &#34;module&#34;: &#34;LightGBM&#34;,
                    &#34;args&#34;: {
                        &#34;stop_after&#34;: &#34;$problem_definition.seconds_per_mixer&#34;,
                        &#34;fit_on_dev&#34;: true
                    }
                },
                {
                    &#34;module&#34;: &#34;Regression&#34;,
                    &#34;args&#34;: {
                        &#34;stop_after&#34;: &#34;$problem_definition.seconds_per_mixer&#34;
                    }
                },
                {
                    &#34;module&#34;: &#34;RandomForest&#34;,
                    &#34;args&#34;: {
                        &#34;stop_after&#34;: &#34;$problem_definition.seconds_per_mixer&#34;,
                        &#34;fit_on_dev&#34;: true
                    }
                }
            ]
        }
    },
    &#34;problem_definition&#34;: {
        &#34;target&#34;: &#34;target&#34;,
        &#34;pct_invalid&#34;: 2,
        &#34;unbias_target&#34;: true,
        &#34;seconds_per_mixer&#34;: 21384.0,
        &#34;seconds_per_encoder&#34;: 85536.0,
        &#34;expected_additional_time&#34;: 20.617971897125244,
        &#34;time_aim&#34;: 259200,
        &#34;target_weights&#34;: null,
        &#34;positive_domain&#34;: false,
        &#34;timeseries_settings&#34;: {
            &#34;is_timeseries&#34;: false,
            &#34;order_by&#34;: null,
            &#34;window&#34;: null,
            &#34;group_by&#34;: null,
            &#34;use_previous_target&#34;: true,
            &#34;horizon&#34;: null,
            &#34;historical_columns&#34;: null,
            &#34;target_type&#34;: &#34;&#34;,
            &#34;allow_incomplete_history&#34;: true,
            &#34;eval_incomplete&#34;: false,
            &#34;interval_periods&#34;: []
        },
        &#34;anomaly_detection&#34;: false,
        &#34;use_default_analysis&#34;: true,
        &#34;dtype_dict&#34;: {},
        &#34;ignore_features&#34;: [
            &#34;url_legal&#34;,
            &#34;license&#34;,
            &#34;standard_error&#34;
        ],
        &#34;fit_on_all&#34;: true,
        &#34;strict_mode&#34;: true,
        &#34;seed_nr&#34;: 1
    },
    &#34;identifiers&#34;: {
        &#34;id&#34;: &#34;Hash-like identifier&#34;
    },
    &#34;imputers&#34;: [],
    &#34;accuracy_functions&#34;: [
        &#34;r2_score&#34;
    ]
}
</pre></div></div>
</div>
<p>The above shows the minimal syntax required to create a functional JSON-AI object. For each feature you consider in the dataset, we specify the name of the feature, the type of encoder (feature-engineering method) to process the feature, and key word arguments to process the encoder. For the output, we perform a similar operation, but specify the types of mixers, or algorithms used in making a predictor that can estimate the target. Lastly, we populate the “problem_definition” key with the
ingredients for our ML pipeline.</p>
<p>These are the only elements required to get off the ground with JSON-AI. However, we’re interested in making a <em>custom</em> approach. So, let’s make this syntax a file, and introduce our own changes.</p>
</div>
<div class="section" id="3)-Build-your-own-cleaner-module">
<h3>3) Build your own cleaner module<a class="headerlink" href="#3)-Build-your-own-cleaner-module" title="Permalink to this headline">¶</a></h3>
<p>Let’s make a file called <code class="docutils literal notranslate"><span class="pre">MyCustomCleaner.py</span></code>. To write this file, we will use <code class="docutils literal notranslate"><span class="pre">dataprep_ml.cleaners.cleaner</span></code> as inspiration. <code class="docutils literal notranslate"><span class="pre">dataprep_ml</span></code> is a companion library that is part of the broader MindsDB ecosystem, and specializes in data cleaning, data splitting and data analysis.</p>
<p>The goal output of the cleaner is to provide pre-processing to your dataset - the output is only a pandas DataFrame. In theory, any pre-processing can be done here. However, data can be highly irregular - our default <code class="docutils literal notranslate"><span class="pre">Cleaner</span></code> function has several main goals:</p>
<ol class="arabic simple">
<li><p>Strip away any identifier, etc. unwanted columns</p></li>
<li><p>Apply a cleaning function to each column in the dataset, according to that column’s data type</p></li>
<li><p>Standardize NaN values within each column for appropriate downstream treatment</p></li>
</ol>
<p>You can choose to omit many of these details and completely write this module from scratch, but the easiest way to introduce your custom changes is to borrow the <code class="docutils literal notranslate"><span class="pre">Cleaner</span></code> function, and add core changes in a custom block.</p>
<p>This can be done as follows</p>
<p>You can see individual cleaning functions in <code class="docutils literal notranslate"><span class="pre">dataprep_ml.cleaners</span></code>. If you want to entirely replace a cleaning technique given a particular data-type, we invite you to change <code class="docutils literal notranslate"><span class="pre">dataprep_ml.cleaners.get_cleaning_func</span></code> using the argument <code class="docutils literal notranslate"><span class="pre">custom_cleaning_functions</span></code>; in this dictionary, for a datatype (specified in <code class="docutils literal notranslate"><span class="pre">type_infer.dtype</span></code>), you can assign your own function to override our defaults.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>%%writefile MyCustomCleaner.py

import numpy as np
import pandas as pd
from type_infer.dtype import dtype

from lightwood.helpers import text
from lightwood.helpers.log import log
from lightwood.api.types import TimeseriesSettings

from nltk.corpus import stopwords

stop_words = set(stopwords.words(&quot;english&quot;))

from typing import Dict

# Borrow cleaner functions
from dataprep_ml.cleaners import (
    _remove_columns,
    _get_columns_to_clean,
    get_cleaning_func,
)

# Use for standardizing NaNs
VALUES_FOR_NAN_AND_NONE_IN_PANDAS = [np.nan, &quot;nan&quot;, &quot;NaN&quot;, &quot;Nan&quot;, &quot;None&quot;]


def cleaner(
    data: pd.DataFrame,
    dtype_dict: Dict[str, str],
    identifiers: Dict[str, str],
    target: str,
    mode: str,
    timeseries_settings: TimeseriesSettings,
    anomaly_detection: bool,
    custom_cleaning_functions: Dict[str, str] = {},
) -&gt; pd.DataFrame:
    &quot;&quot;&quot;
    The cleaner is a function which takes in the raw data, plus additional information about it&#39;s types and about the problem. Based on this it generates a &quot;clean&quot; representation of the data, where each column has an ideal standardized type and all malformed or otherwise missing or invalid elements are turned into ``None``

    :param data: The raw data
    :param dtype_dict: Type information for each column
    :param identifiers: A dict containing all identifier typed columns
    :param target: The target columns
    :param mode: Can be &quot;predict&quot; or &quot;train&quot;
    :param timeseries_settings: Timeseries related settings, only relevant for timeseries predictors, otherwise can be the default object
    :param anomaly_detection: Are we detecting anomalies with this predictor?

    :returns: The cleaned data
    &quot;&quot;&quot;  # noqa

    data = _remove_columns(
        data,
        identifiers,
        target,
        mode,
        timeseries_settings,
        anomaly_detection,
        dtype_dict,
    )

    for col in _get_columns_to_clean(data, dtype_dict, mode, target):

        log.info(&quot;Cleaning column =&quot; + str(col))
        # Get and apply a cleaning function for each data type
        # If you want to customize the cleaner, it&#39;s likely you can to modify ``get_cleaning_func``
        data[col] = data[col].apply(
            get_cleaning_func(dtype_dict[col], custom_cleaning_functions)
        )

        # ------------------------ #
        # INTRODUCE YOUR CUSTOM BLOCK

        # If column data type is a text type, remove stop-words
        if dtype_dict[col] in (dtype.rich_text, dtype.short_text):
            data[col] = data[col].apply(
                lambda x: &quot; &quot;.join(
                    [word for word in x.split() if word not in stop_words]
                )
            )

        # Enforce numerical columns as non-negative
        if dtype_dict[col] in (dtype.integer, dtype.float):
            log.info(&quot;Converted &quot; + str(col) + &quot; into strictly non-negative&quot;)
            data[col] = data[col].apply(lambda x: x if x &gt; 0 else 0.0)

        # ------------------------ #
        data[col] = data[col].replace(
            to_replace=VALUES_FOR_NAN_AND_NONE_IN_PANDAS, value=None
        )

    return data
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Writing MyCustomCleaner.py
</pre></div></div>
</div>
</div>
</div>
<div class="section" id="Place-your-custom-module-in-~/lightwood_modules-or-/etc/lightwood_modules">
<h2>Place your custom module in <code class="docutils literal notranslate"><span class="pre">~/lightwood_modules</span></code> or <code class="docutils literal notranslate"><span class="pre">/etc/lightwood_modules</span></code><a class="headerlink" href="#Place-your-custom-module-in-~/lightwood_modules-or-/etc/lightwood_modules" title="Permalink to this headline">¶</a></h2>
<p>We automatically search for custom scripts in your <code class="docutils literal notranslate"><span class="pre">~/lightwood_modules</span></code> and <code class="docutils literal notranslate"><span class="pre">/etc/lightwood_modules</span></code> path. Place your file there. Later, you’ll see when we autogenerate code, that you can change your import location if you choose.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from lightwood import load_custom_module

# Lightwood automatically does this for us if we want
load_custom_module(&#39;MyCustomCleaner.py&#39;)
</pre></div>
</div>
</div>
<div class="section" id="4)-Introduce-your-custom-cleaner-in-JSON-AI">
<h3>4) Introduce your custom cleaner in JSON-AI<a class="headerlink" href="#4)-Introduce-your-custom-cleaner-in-JSON-AI" title="Permalink to this headline">¶</a></h3>
<p>Now let’s introduce our custom cleaner. JSON-AI keeps a lightweight syntax but fills in many default modules (like splitting, cleaning). As you can see, it is also agnostic to the origin of the module, as long as it behaves as expected of the other modules that could be used in any given key.</p>
<p>For the custom cleaner, we’ll work by editing the “cleaner” key. We will change properties within it as follows: (1) “module” - place the name of the function. In our case it will be “MyCustomCleaner.cleaner” (2) “args” - any keyword argument specific to your cleaner’s internals.</p>
<p>This will look as follows:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>&quot;cleaner&quot;: {
    &quot;module&quot;: &quot;MyCustomCleaner.cleaner&quot;,
    &quot;args&quot;: {
        &quot;identifiers&quot;: &quot;$identifiers&quot;,
        &quot;data&quot;: &quot;data&quot;,
        &quot;dtype_dict&quot;: &quot;$dtype_dict&quot;,
        &quot;target&quot;: &quot;$target&quot;,
        &quot;mode&quot;: &quot;$mode&quot;,
        &quot;timeseries_settings&quot;: &quot;$problem_definition.timeseries_settings&quot;,
        &quot;anomaly_detection&quot;: &quot;$problem_definition.anomaly_detection&quot;
    }
</pre></div>
</div>
<p>You may be wondering what the “$” variables reference. In certain cases, we’d like JSON-AI to auto-fill internal variables when automatically generating code, for example, we’ve already specified the “target” - it would be easier to simply refer in a modular sense what that term is. That is what these variables represent.</p>
<p>As we borrowed most of the default <code class="docutils literal notranslate"><span class="pre">Cleaner</span></code>; we keep these arguments. In theory, if we were writing much of these details from scratch, we can customize these values as necessary.</p>
</div>
<div class="section" id="5)-Generate-Python-code-representing-your-ML-pipeline">
<h3>5) Generate Python code representing your ML pipeline<a class="headerlink" href="#5)-Generate-Python-code-representing-your-ML-pipeline" title="Permalink to this headline">¶</a></h3>
<p>Now we’re ready to load up our custom JSON-AI and generate the predictor code!</p>
<p>We can do this by first reading in our custom json-syntax, and then calling the function <code class="docutils literal notranslate"><span class="pre">code_from_json_ai</span></code>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Make changes to your JSON-AI
json_ai.cleaner = {
        &quot;module&quot;: &quot;MyCustomCleaner.cleaner&quot;,
        &quot;args&quot;: {
            &quot;identifiers&quot;: &quot;$identifiers&quot;,
            &quot;data&quot;: &quot;data&quot;,
            &quot;dtype_dict&quot;: &quot;$dtype_dict&quot;,
            &quot;target&quot;: &quot;$target&quot;,
            &quot;mode&quot;: &quot;$mode&quot;,
            &quot;timeseries_settings&quot;: &quot;$problem_definition.timeseries_settings.to_dict()&quot;,
            &quot;anomaly_detection&quot;: &quot;$problem_definition.anomaly_detection&quot;
        }
}

#Generate python code that fills in your pipeline
code = code_from_json_ai(json_ai)

print(code)

# Save code to a file (Optional)
with open(&#39;custom_cleaner_pipeline.py&#39;, &#39;w&#39;) as fp:
    fp.write(code)
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
<span class="ansi-green-fg">INFO:dataprep_ml-2356:Unable to import black formatter, predictor code might be a bit ugly.</span>
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
import lightwood
from lightwood import __version__ as lightwood_version
from lightwood.analysis import *
from lightwood.api import *
from lightwood.data import *
from lightwood.encoder import *
from lightwood.ensemble import *
from lightwood.helpers.device import *
from lightwood.helpers.general import *
from lightwood.helpers.ts import *
from lightwood.helpers.log import *
from lightwood.helpers.numeric import *
from lightwood.helpers.parallelism import *
from lightwood.helpers.seed import *
from lightwood.helpers.text import *
from lightwood.helpers.torch import *
from lightwood.mixer import *

from dataprep_ml.insights import statistical_analysis
from dataprep_ml.cleaners import cleaner
from dataprep_ml.splitters import splitter
from dataprep_ml.imputers import *

import pandas as pd
from typing import Dict, List, Union
import os
from types import ModuleType
import importlib.machinery
import sys
import time


for import_dir in [
    os.path.join(
        os.path.expanduser(&#34;~/lightwood_modules&#34;), lightwood_version.replace(&#34;.&#34;, &#34;_&#34;)
    ),
    os.path.join(&#34;/etc/lightwood_modules&#34;, lightwood_version.replace(&#34;.&#34;, &#34;_&#34;)),
]:
    if os.path.exists(import_dir) and os.access(import_dir, os.R_OK):
        for file_name in list(os.walk(import_dir))[0][2]:
            if file_name[-3:] != &#34;.py&#34;:
                continue
            mod_name = file_name[:-3]
            loader = importlib.machinery.SourceFileLoader(
                mod_name, os.path.join(import_dir, file_name)
            )
            module = ModuleType(loader.name)
            loader.exec_module(module)
            sys.modules[mod_name] = module
            exec(f&#34;import {mod_name}&#34;)


class Predictor(PredictorInterface):
    target: str
    mixers: List[BaseMixer]
    encoders: Dict[str, BaseEncoder]
    ensemble: BaseEnsemble
    mode: str

    def __init__(self):
        seed(1)
        self.target = &#34;target&#34;
        self.mode = &#34;inactive&#34;
        self.problem_definition = ProblemDefinition.from_dict(
            {
                &#34;target&#34;: &#34;target&#34;,
                &#34;pct_invalid&#34;: 2,
                &#34;unbias_target&#34;: True,
                &#34;seconds_per_mixer&#34;: 21384.0,
                &#34;seconds_per_encoder&#34;: 85536.0,
                &#34;expected_additional_time&#34;: 20.617971897125244,
                &#34;time_aim&#34;: 259200,
                &#34;target_weights&#34;: None,
                &#34;positive_domain&#34;: False,
                &#34;timeseries_settings&#34;: {
                    &#34;is_timeseries&#34;: False,
                    &#34;order_by&#34;: None,
                    &#34;window&#34;: None,
                    &#34;group_by&#34;: None,
                    &#34;use_previous_target&#34;: True,
                    &#34;horizon&#34;: None,
                    &#34;historical_columns&#34;: None,
                    &#34;target_type&#34;: &#34;&#34;,
                    &#34;allow_incomplete_history&#34;: True,
                    &#34;eval_incomplete&#34;: False,
                    &#34;interval_periods&#34;: [],
                },
                &#34;anomaly_detection&#34;: False,
                &#34;use_default_analysis&#34;: True,
                &#34;dtype_dict&#34;: {},
                &#34;ignore_features&#34;: [&#34;url_legal&#34;, &#34;license&#34;, &#34;standard_error&#34;],
                &#34;fit_on_all&#34;: True,
                &#34;strict_mode&#34;: True,
                &#34;seed_nr&#34;: 1,
            }
        )
        self.accuracy_functions = [&#34;r2_score&#34;]
        self.identifiers = {&#34;id&#34;: &#34;Hash-like identifier&#34;}
        self.dtype_dict = {&#34;excerpt&#34;: &#34;rich_text&#34;, &#34;target&#34;: &#34;float&#34;}
        self.lightwood_version = &#34;22.12.1.0&#34;

        # Any feature-column dependencies
        self.dependencies = {&#34;target&#34;: [], &#34;excerpt&#34;: []}

        self.input_cols = [&#34;excerpt&#34;]

        # Initial stats analysis
        self.statistical_analysis = None
        self.ts_analysis = None
        self.runtime_log = dict()

    @timed
    def analyze_data(self, data: pd.DataFrame) -&gt; None:
        # Perform a statistical analysis on the unprocessed data

        self.statistical_analysis = statistical_analysis(
            data,
            self.dtype_dict,
            self.problem_definition.to_dict(),
            {&#34;id&#34;: &#34;Hash-like identifier&#34;},
        )

        # Instantiate post-training evaluation
        self.analysis_blocks = [
            ICP(fixed_significance=None, confidence_normalizer=False, deps=[]),
            ConfStats(deps=[&#34;ICP&#34;]),
            AccStats(deps=[&#34;ICP&#34;]),
            PermutationFeatureImportance(deps=[&#34;AccStats&#34;]),
        ]

    @timed
    def preprocess(self, data: pd.DataFrame) -&gt; pd.DataFrame:
        # Preprocess and clean data

        log.info(&#34;Cleaning the data&#34;)
        self.imputers = {}
        data = MyCustomCleaner.cleaner(
            data=data,
            identifiers=self.identifiers,
            dtype_dict=self.dtype_dict,
            target=self.target,
            mode=self.mode,
            timeseries_settings=self.problem_definition.timeseries_settings.to_dict(),
            anomaly_detection=self.problem_definition.anomaly_detection,
        )

        # Time-series blocks

        return data

    @timed
    def split(self, data: pd.DataFrame) -&gt; Dict[str, pd.DataFrame]:
        # Split the data into training/testing splits

        log.info(&#34;Splitting the data into train/test&#34;)
        train_test_data = splitter(
            data=data,
            pct_train=0.8,
            pct_dev=0.1,
            pct_test=0.1,
            tss=self.problem_definition.timeseries_settings.to_dict(),
            seed=self.problem_definition.seed_nr,
            target=self.target,
            dtype_dict=self.dtype_dict,
        )

        return train_test_data

    @timed
    def prepare(self, data: Dict[str, pd.DataFrame]) -&gt; None:
        # Prepare encoders to featurize data

        self.mode = &#34;train&#34;

        if self.statistical_analysis is None:
            raise Exception(&#34;Please run analyze_data first&#34;)

        # Column to encoder mapping
        self.encoders = {
            &#34;target&#34;: NumericEncoder(
                is_target=True,
                positive_domain=self.statistical_analysis.positive_domain,
            ),
            &#34;excerpt&#34;: PretrainedLangEncoder(
                output_type=self.dtype_dict[self.target],
                stop_after=self.problem_definition.seconds_per_encoder,
            ),
        }

        # Prepare the training + dev data
        concatenated_train_dev = pd.concat([data[&#34;train&#34;], data[&#34;dev&#34;]])

        encoder_prepping_dict = {}

        # Prepare encoders that do not require learned strategies
        for col_name, encoder in self.encoders.items():
            if col_name != self.target and not encoder.is_trainable_encoder:
                encoder_prepping_dict[col_name] = [
                    encoder,
                    concatenated_train_dev[col_name],
                    &#34;prepare&#34;,
                ]

        # Setup parallelization
        parallel_prepped_encoders = mut_method_call(encoder_prepping_dict)
        for col_name, encoder in parallel_prepped_encoders.items():
            self.encoders[col_name] = encoder

        # Prepare the target
        if self.target not in parallel_prepped_encoders:
            if self.encoders[self.target].is_trainable_encoder:
                self.encoders[self.target].prepare(
                    data[&#34;train&#34;][self.target], data[&#34;dev&#34;][self.target]
                )
            else:
                self.encoders[self.target].prepare(
                    pd.concat([data[&#34;train&#34;], data[&#34;dev&#34;]])[self.target]
                )

        # Prepare any non-target encoders that are learned
        for col_name, encoder in self.encoders.items():
            if col_name != self.target and encoder.is_trainable_encoder:
                priming_data = pd.concat([data[&#34;train&#34;], data[&#34;dev&#34;]])
                kwargs = {}
                if self.dependencies[col_name]:
                    kwargs[&#34;dependency_data&#34;] = {}
                    for col in self.dependencies[col_name]:
                        kwargs[&#34;dependency_data&#34;][col] = {
                            &#34;original_type&#34;: self.dtype_dict[col],
                            &#34;data&#34;: priming_data[col],
                        }

                # If an encoder representation requires the target, provide priming data
                if hasattr(encoder, &#34;uses_target&#34;):
                    kwargs[&#34;encoded_target_values&#34;] = self.encoders[self.target].encode(
                        priming_data[self.target]
                    )

                encoder.prepare(
                    data[&#34;train&#34;][col_name], data[&#34;dev&#34;][col_name], **kwargs
                )

    @timed
    def featurize(self, split_data: Dict[str, pd.DataFrame]):
        # Featurize data into numerical representations for models

        log.info(&#34;Featurizing the data&#34;)

        feature_data = {
            key: EncodedDs(self.encoders, data, self.target)
            for key, data in split_data.items()
            if key != &#34;stratified_on&#34;
        }

        return feature_data

    @timed
    def fit(self, enc_data: Dict[str, pd.DataFrame]) -&gt; None:
        # Fit predictors to estimate target

        self.mode = &#34;train&#34;

        # --------------- #
        # Extract data
        # --------------- #
        # Extract the featurized data into train/dev/test
        encoded_train_data = enc_data[&#34;train&#34;]
        encoded_dev_data = enc_data[&#34;dev&#34;]
        encoded_test_data = enc_data[&#34;test&#34;]
        filtered_df = filter_ds(
            encoded_test_data, self.problem_definition.timeseries_settings
        )
        encoded_test_data = EncodedDs(
            encoded_test_data.encoders, filtered_df, encoded_test_data.target
        )

        log.info(&#34;Training the mixers&#34;)

        # --------------- #
        # Fit Models
        # --------------- #
        # Assign list of mixers
        self.mixers = [
            Neural(
                fit_on_dev=True,
                search_hyperparameters=True,
                net=&#34;DefaultNet&#34;,
                stop_after=self.problem_definition.seconds_per_mixer,
                target=self.target,
                dtype_dict=self.dtype_dict,
                target_encoder=self.encoders[self.target],
            ),
            LightGBM(
                fit_on_dev=True,
                use_optuna=True,
                stop_after=self.problem_definition.seconds_per_mixer,
                target=self.target,
                dtype_dict=self.dtype_dict,
                input_cols=self.input_cols,
                target_encoder=self.encoders[self.target],
            ),
            Regression(
                stop_after=self.problem_definition.seconds_per_mixer,
                target=self.target,
                dtype_dict=self.dtype_dict,
                target_encoder=self.encoders[self.target],
            ),
            RandomForest(
                fit_on_dev=True,
                use_optuna=True,
                stop_after=self.problem_definition.seconds_per_mixer,
                target=self.target,
                dtype_dict=self.dtype_dict,
                target_encoder=self.encoders[self.target],
            ),
        ]

        # Train mixers
        trained_mixers = []
        for mixer in self.mixers:
            try:
                self.fit_mixer(mixer, encoded_train_data, encoded_dev_data)
                trained_mixers.append(mixer)
            except Exception as e:
                log.warning(f&#34;Exception: {e} when training mixer: {mixer}&#34;)
                if True and mixer.stable:
                    raise e

        # Update mixers to trained versions
        self.mixers = trained_mixers

        # --------------- #
        # Create Ensembles
        # --------------- #
        log.info(&#34;Ensembling the mixer&#34;)
        # Create an ensemble of mixers to identify best performing model
        self.pred_args = PredictionArguments()
        # Dirty hack
        self.ensemble = BestOf(
            data=encoded_test_data,
            fit=True,
            ts_analysis=None,
            target=self.target,
            mixers=self.mixers,
            args=self.pred_args,
            accuracy_functions=self.accuracy_functions,
        )
        self.supports_proba = self.ensemble.supports_proba

    @timed
    def fit_mixer(self, mixer, encoded_train_data, encoded_dev_data) -&gt; None:
        mixer.fit(encoded_train_data, encoded_dev_data)

    @timed
    def analyze_ensemble(self, enc_data: Dict[str, pd.DataFrame]) -&gt; None:
        # Evaluate quality of fit for the ensemble of mixers

        # --------------- #
        # Extract data
        # --------------- #
        # Extract the featurized data into train/dev/test
        encoded_train_data = enc_data[&#34;train&#34;]
        encoded_dev_data = enc_data[&#34;dev&#34;]
        encoded_test_data = enc_data[&#34;test&#34;]

        # --------------- #
        # Analyze Ensembles
        # --------------- #
        log.info(&#34;Analyzing the ensemble of mixers&#34;)
        self.model_analysis, self.runtime_analyzer = model_analyzer(
            data=encoded_test_data,
            train_data=encoded_train_data,
            ts_analysis=None,
            stats_info=self.statistical_analysis,
            tss=self.problem_definition.timeseries_settings,
            accuracy_functions=self.accuracy_functions,
            predictor=self.ensemble,
            target=self.target,
            dtype_dict=self.dtype_dict,
            analysis_blocks=self.analysis_blocks,
        )

    @timed
    def learn(self, data: pd.DataFrame) -&gt; None:
        if self.problem_definition.ignore_features:
            log.info(f&#34;Dropping features: {self.problem_definition.ignore_features}&#34;)
            data = data.drop(
                columns=self.problem_definition.ignore_features, errors=&#34;ignore&#34;
            )

        self.mode = &#34;train&#34;
        n_phases = 8 if self.problem_definition.fit_on_all else 7

        # Perform stats analysis
        log.info(f&#34;[Learn phase 1/{n_phases}] - Statistical analysis&#34;)
        self.analyze_data(data)

        # Pre-process the data
        log.info(f&#34;[Learn phase 2/{n_phases}] - Data preprocessing&#34;)
        data = self.preprocess(data)

        # Create train/test (dev) split
        log.info(f&#34;[Learn phase 3/{n_phases}] - Data splitting&#34;)
        train_dev_test = self.split(data)

        # Prepare encoders
        log.info(f&#34;[Learn phase 4/{n_phases}] - Preparing encoders&#34;)
        self.prepare(train_dev_test)

        # Create feature vectors from data
        log.info(f&#34;[Learn phase 5/{n_phases}] - Feature generation&#34;)
        enc_train_test = self.featurize(train_dev_test)

        # Prepare mixers
        log.info(f&#34;[Learn phase 6/{n_phases}] - Mixer training&#34;)
        self.fit(enc_train_test)

        # Analyze the ensemble
        log.info(f&#34;[Learn phase 7/{n_phases}] - Ensemble analysis&#34;)
        self.analyze_ensemble(enc_train_test)

        # ------------------------ #
        # Enable model partial fit AFTER it is trained and evaluated for performance with the appropriate train/dev/test splits.
        # This assumes the predictor could continuously evolve, hence including reserved testing data may improve predictions.
        # SET `json_ai.problem_definition.fit_on_all=False` TO TURN THIS BLOCK OFF.

        # Update the mixers with partial fit
        if self.problem_definition.fit_on_all:

            log.info(f&#34;[Learn phase 8/{n_phases}] - Adjustment on validation requested&#34;)
            self.adjust(
                enc_train_test[&#34;test&#34;].data_frame,
                ConcatedEncodedDs(
                    [enc_train_test[&#34;train&#34;], enc_train_test[&#34;dev&#34;]]
                ).data_frame,
                adjust_args={&#34;learn_call&#34;: True},
            )

    @timed
    def adjust(
        self,
        train_data: Union[EncodedDs, ConcatedEncodedDs, pd.DataFrame],
        dev_data: Optional[Union[EncodedDs, ConcatedEncodedDs, pd.DataFrame]] = None,
        adjust_args: Optional[dict] = None,
    ) -&gt; None:
        # Update mixers with new information

        self.mode = &#34;train&#34;

        # --------------- #
        # Prepare data
        # --------------- #
        if dev_data is None:
            data = train_data
            split = splitter(
                data=data,
                pct_train=0.8,
                pct_dev=0.2,
                pct_test=0,
                tss=self.problem_definition.timeseries_settings.to_dict(),
                seed=self.problem_definition.seed_nr,
                target=self.target,
                dtype_dict=self.dtype_dict,
            )
            train_data = split[&#34;train&#34;]
            dev_data = split[&#34;dev&#34;]

        if adjust_args is None or not adjust_args.get(&#34;learn_call&#34;):
            train_data = self.preprocess(train_data)
            dev_data = self.preprocess(dev_data)

        dev_data = EncodedDs(self.encoders, dev_data, self.target)
        train_data = EncodedDs(self.encoders, train_data, self.target)

        # --------------- #
        # Update/Adjust Mixers
        # --------------- #
        log.info(&#34;Updating the mixers&#34;)

        for mixer in self.mixers:
            mixer.partial_fit(train_data, dev_data, adjust_args)

    @timed
    def predict(self, data: pd.DataFrame, args: Dict = {}) -&gt; pd.DataFrame:

        self.mode = &#34;predict&#34;
        n_phases = 3 if self.pred_args.all_mixers else 4

        if len(data) == 0:
            raise Exception(
                &#34;Empty input, aborting prediction. Please try again with some input data.&#34;
            )

        log.info(f&#34;[Predict phase 1/{n_phases}] - Data preprocessing&#34;)
        if self.problem_definition.ignore_features:
            log.info(f&#34;Dropping features: {self.problem_definition.ignore_features}&#34;)
            data = data.drop(
                columns=self.problem_definition.ignore_features, errors=&#34;ignore&#34;
            )
        for col in self.input_cols:
            if col not in data.columns:
                data[col] = [None] * len(data)

        # Pre-process the data
        data = self.preprocess(data)

        # Featurize the data
        log.info(f&#34;[Predict phase 2/{n_phases}] - Feature generation&#34;)
        encoded_ds = self.featurize({&#34;predict_data&#34;: data})[&#34;predict_data&#34;]
        encoded_data = encoded_ds.get_encoded_data(include_target=False)

        log.info(f&#34;[Predict phase 3/{n_phases}] - Calling ensemble&#34;)
        self.pred_args = PredictionArguments.from_dict(args)
        df = self.ensemble(encoded_ds, args=self.pred_args)

        if self.pred_args.all_mixers:
            return df
        else:
            log.info(f&#34;[Predict phase 4/{n_phases}] - Analyzing output&#34;)
            insights, global_insights = explain(
                data=data,
                encoded_data=encoded_data,
                predictions=df,
                ts_analysis=None,
                problem_definition=self.problem_definition,
                stat_analysis=self.statistical_analysis,
                runtime_analysis=self.runtime_analyzer,
                target_name=self.target,
                target_dtype=self.dtype_dict[self.target],
                explainer_blocks=self.analysis_blocks,
                pred_args=self.pred_args,
            )
            return insights

</pre></div></div>
</div>
<p>As you can see, an end-to-end pipeline of our entire ML procedure has been generating. There are several abstracted functions to enable transparency as to what processes your data goes through in order to build these models.</p>
<p>The key steps of the pipeline are as follows:</p>
<ol class="arabic simple">
<li><p>Run a <strong>statistical analysis</strong> with <code class="docutils literal notranslate"><span class="pre">analyze_data</span></code></p></li>
<li><p>Clean your data with <code class="docutils literal notranslate"><span class="pre">preprocess</span></code></p></li>
<li><p>Make a training/dev/testing split with <code class="docutils literal notranslate"><span class="pre">split</span></code></p></li>
<li><p>Prepare your feature-engineering pipelines with <code class="docutils literal notranslate"><span class="pre">prepare</span></code></p></li>
<li><p>Create your features with <code class="docutils literal notranslate"><span class="pre">featurize</span></code></p></li>
<li><p>Fit your predictor models with <code class="docutils literal notranslate"><span class="pre">fit</span></code></p></li>
</ol>
<p>You can customize this further if necessary, but you have all the steps necessary to train a model!</p>
<p>We recommend familiarizing with these steps by calling the above commands, ideally in order. Some commands (namely <code class="docutils literal notranslate"><span class="pre">prepare</span></code>, <code class="docutils literal notranslate"><span class="pre">featurize</span></code>, and <code class="docutils literal notranslate"><span class="pre">fit</span></code>) do depend on other steps.</p>
<p>If you want to omit the individual steps, we recommend your simply call the <code class="docutils literal notranslate"><span class="pre">learn</span></code> method, which compiles all the necessary steps implemented to give your fully trained predictive models starting with unprocessed data!</p>
</div>
<div class="section" id="6)-Call-python-to-run-your-code-and-see-your-preprocessed-outputs">
<h3>6) Call python to run your code and see your preprocessed outputs<a class="headerlink" href="#6)-Call-python-to-run-your-code-and-see-your-preprocessed-outputs" title="Permalink to this headline">¶</a></h3>
<p>Once we have code, we can turn this into a python object by calling <code class="docutils literal notranslate"><span class="pre">predictor_from_code</span></code>. This instantiates the <code class="docutils literal notranslate"><span class="pre">PredictorInterface</span></code> object.</p>
<p>This predictor object can be then used to run your pipeline.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Turn the code above into a predictor object
predictor = predictor_from_code(code)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>predictor.mode = &quot;train&quot;

# Perform stats analysis
predictor.analyze_data(data)

# Pre-process the data
cleaned_data = predictor.preprocess(data)

cleaned_data.head()
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
<span class="ansi-green-fg">INFO:dataprep_ml-2356:Starting statistical analysis</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2356:Dropping features: [&#39;id&#39;]</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2356:Finished statistical analysis</span>
<span class="ansi-white-fg">DEBUG:lightwood-2356: `analyze_data` runtime: 0.06 seconds</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2356:Cleaning the data</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2356:Dropping features: [&#39;id&#39;]</span>
<span class="ansi-green-fg">INFO:lightwood-2356:Cleaning column =excerpt</span>
<span class="ansi-green-fg">INFO:lightwood-2356:Cleaning column =target</span>
<span class="ansi-green-fg">INFO:lightwood-2356:Converted target into strictly non-negative</span>
<span class="ansi-white-fg">DEBUG:lightwood-2356: `preprocess` runtime: 0.12 seconds</span>
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>excerpt</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>When young people returned ballroom, presented...</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>All dinner time, Mrs. Fayre somewhat silent, e...</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>As Roger predicted, snow departed quickly came...</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>And outside palace great garden walled round, ...</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Once upon time Three Bears lived together hous...</td>
      <td>0.247197</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>print(&quot;\033[1m&quot;  + &quot;Original Data\n&quot; + &quot;\033[0m&quot;)
print(&quot;Excerpt:\n&quot;, data.iloc[0][&quot;excerpt&quot;])
print(&quot;\nTarget:\n&quot;, data.iloc[0][&quot;target&quot;])

print(&quot;\033[1m&quot;  + &quot;\n\nCleaned Data\n&quot; + &quot;\033[0m&quot;)
print(&quot;Excerpt:\n&quot;, cleaned_data.iloc[0][&quot;excerpt&quot;])
print(&quot;\nTarget:\n&quot;, cleaned_data.iloc[0][&quot;target&quot;])
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-bold">Original Data
</span>
Excerpt:
 When the young people returned to the ballroom, it presented a decidedly changed appearance. Instead of an interior scene, it was a winter landscape.
The floor was covered with snow-white canvas, not laid on smoothly, but rumpled over bumps and hillocks, like a real snow field. The numerous palms and evergreens that had decorated the room, were powdered with flour and strewn with tufts of cotton, like snow. Also diamond dust had been lightly sprinkled on them, and glittering crystal icicles hung from the branches.
At each end of the room, on the wall, hung a beautiful bear-skin rug.
These rugs were for prizes, one for the girls and one for the boys. And this was the game.
The girls were gathered at one end of the room and the boys at the other, and one end was called the North Pole, and the other the South Pole. Each player was given a small flag which they were to plant on reaching the Pole.
This would have been an easy matter, but each traveller was obliged to wear snowshoes.

Target:
 -0.340259125
<span class="ansi-bold">

Cleaned Data
</span>
Excerpt:
 When young people returned ballroom, presented decidedly changed appearance. Instead interior scene, winter landscape. The floor covered snow-white canvas, laid smoothly, rumpled bumps hillocks, like real snow field. The numerous palms evergreens decorated room, powdered flour strewn tufts cotton, like snow. Also diamond dust lightly sprinkled them, glittering crystal icicles hung branches. At end room, wall, hung beautiful bear-skin rug. These rugs prizes, one girls one boys. And game. The girls gathered one end room boys other, one end called North Pole, South Pole. Each player given small flag plant reaching Pole. This would easy matter, traveller obliged wear snowshoes.

Target:
 0.0
</pre></div></div>
</div>
<p>As you can see, the cleaning-process we introduced cut out the stop-words from the Excerpt, and enforced the target data to stay positive.</p>
<p>We hope this tutorial was informative on how to introduce a <strong>custom preprocessing method</strong> to your datasets! For more customization tutorials, please check our <a class="reference external" href="https://lightwood.io/tutorials.html">documentation</a>.</p>
<p>If you want to download the Jupyter-notebook version of this tutorial, check out the source github location found here: <code class="docutils literal notranslate"><span class="pre">lightwood/docssrc/source/tutorials/custom_cleaner</span></code>.</p>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2017-2022, MindsDB.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>


<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Tutorial - Time series forecasting &mdash; lightwood 23.3.2.0 documentation</title>
  

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/graphviz.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: white" >
          

          
            <a href="../../index.html">
          

          
            
            <img src="../../_static/mindsdblogo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                23.3.2.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Tutorials</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">API</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../data.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Data</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../encoder.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Encoders</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mixer.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Mixers</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ensemble.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Ensemble</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../analysis.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Analysis</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../helpers.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Helpers</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../lightwood_philosophy.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Lightwood</span> <span class="pre">Philosophy</span></code></a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">lightwood</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Tutorial - Time series forecasting</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../_sources/tutorials/tutorial_time_series/tutorial_time_series.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="Tutorial---Time-series-forecasting">
<h1>Tutorial - Time series forecasting<a class="headerlink" href="#Tutorial---Time-series-forecasting" title="Permalink to this headline">¶</a></h1>
<div class="section" id="Introduction">
<h2>Introduction<a class="headerlink" href="#Introduction" title="Permalink to this headline">¶</a></h2>
<p>Time series are an ubiquitous type of data in all types of processes. Producing forecasts for them can be highly valuable in domains like retail or industrial manufacture, among many others.</p>
<p>Lightwood supports time series forecasting (both univariate and multivariate inputs), handling many of the pain points commonly associated with setting up a manual time series predictive pipeline.</p>
<p>In this tutorial, we will train a lightwood predictor and analyze its forecasts for the task of counting sunspots in monthly intervals.</p>
</div>
<div class="section" id="Load-data">
<h2>Load data<a class="headerlink" href="#Load-data" title="Permalink to this headline">¶</a></h2>
<p>Let’s begin by loading the dataset and looking at it:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;https://raw.githubusercontent.com/mindsdb/benchmarks/main/benchmarks/datasets/monthly_sunspots/data.csv&quot;</span><span class="p">)</span>
<span class="n">df</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Month</th>
      <th>Sunspots</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1749-01</td>
      <td>58.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1749-02</td>
      <td>62.6</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1749-03</td>
      <td>70.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1749-04</td>
      <td>55.7</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1749-05</td>
      <td>85.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2815</th>
      <td>1983-08</td>
      <td>71.8</td>
    </tr>
    <tr>
      <th>2816</th>
      <td>1983-09</td>
      <td>50.3</td>
    </tr>
    <tr>
      <th>2817</th>
      <td>1983-10</td>
      <td>55.8</td>
    </tr>
    <tr>
      <th>2818</th>
      <td>1983-11</td>
      <td>33.3</td>
    </tr>
    <tr>
      <th>2819</th>
      <td>1983-12</td>
      <td>33.4</td>
    </tr>
  </tbody>
</table>
<p>2820 rows × 2 columns</p>
</div></div>
</div>
<p>This is a very simple dataset. It’s got a single column that specifies the month in which the measurement was done, and then in the ‘Sunspots’ column we have the actual quantity we are interested in forecasting. As such, we can characterize this as a univariate time series problem.</p>
</div>
<div class="section" id="Define-the-predictive-task">
<h2>Define the predictive task<a class="headerlink" href="#Define-the-predictive-task" title="Permalink to this headline">¶</a></h2>
<p>We will use Lightwood high level methods to state what we want to predict. As this is a time series task (because we want to leverage the notion of time to predict), we need to specify a set of arguments that will activate Lightwood’s time series pipeline:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lightwood.api.high_level</span> <span class="kn">import</span> <span class="n">ProblemDefinition</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
<span class="ansi-green-fg">INFO:lightwood-2386:No torchvision detected, image helpers not supported.</span>
<span class="ansi-green-fg">INFO:lightwood-2386:No torchvision/pillow detected, image encoder not supported</span>
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tss</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;horizon&#39;</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span>   <span class="c1"># the predictor will learn to forecast what the next semester counts will look like (6 data points at monthly intervals -&gt; 6 months)</span>
       <span class="s1">&#39;order_by&#39;</span><span class="p">:</span> <span class="s1">&#39;Month&#39;</span><span class="p">,</span> <span class="c1"># what column is used to order the entire datset</span>
       <span class="s1">&#39;window&#39;</span><span class="p">:</span> <span class="mi">12</span>           <span class="c1"># how many past values to consider for emitting predictions</span>
      <span class="p">}</span>

<span class="n">pdef</span> <span class="o">=</span> <span class="n">ProblemDefinition</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span><span class="s1">&#39;target&#39;</span><span class="p">:</span> <span class="s1">&#39;Sunspots&#39;</span><span class="p">,</span>         <span class="c1"># specify the column to forecast</span>
                                    <span class="s1">&#39;timeseries_settings&#39;</span><span class="p">:</span> <span class="n">tss</span>    <span class="c1"># pass along all time series specific parameters</span>
                                   <span class="p">})</span>
</pre></div>
</div>
</div>
<p>Now, let’s do a very simple train-test split, leaving 10% of the data to check the forecasts that our predictor will produce:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cutoff</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">*</span><span class="mf">0.9</span><span class="p">)</span>

<span class="n">train</span> <span class="o">=</span> <span class="n">df</span><span class="p">[:</span><span class="n">cutoff</span><span class="p">]</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">cutoff</span><span class="p">:]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(2538, 2) (282, 2)
</pre></div></div>
</div>
</div>
<div class="section" id="Generate-the-predictor-object">
<h2>Generate the predictor object<a class="headerlink" href="#Generate-the-predictor-object" title="Permalink to this headline">¶</a></h2>
<p>Now, we can generate code for a machine learning model by using our problem definition and the data:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lightwood.api.high_level</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">json_ai_from_problem</span><span class="p">,</span>
    <span class="n">code_from_json_ai</span><span class="p">,</span>
    <span class="n">predictor_from_code</span>
<span class="p">)</span>

<span class="n">json_ai</span> <span class="o">=</span> <span class="n">json_ai_from_problem</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">problem_definition</span><span class="o">=</span><span class="n">pdef</span><span class="p">)</span>
<span class="n">code</span> <span class="o">=</span> <span class="n">code_from_json_ai</span><span class="p">(</span><span class="n">json_ai</span><span class="p">)</span>
<span class="n">predictor</span> <span class="o">=</span> <span class="n">predictor_from_code</span><span class="p">(</span><span class="n">code</span><span class="p">)</span>

<span class="c1"># uncomment this to see the generated code:</span>
<span class="c1"># print(code)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
<span class="ansi-green-fg">INFO:type_infer-2386:Analyzing a sample of 2467</span>
<span class="ansi-green-fg">INFO:type_infer-2386:from a total population of 2820, this is equivalent to 87.5% of your data.</span>
<span class="ansi-green-fg">INFO:type_infer-2386:Infering type for: Month</span>
<span class="ansi-green-fg">INFO:type_infer-2386:Column Month has data type date</span>
<span class="ansi-green-fg">INFO:type_infer-2386:Infering type for: Sunspots</span>
<span class="ansi-green-fg">INFO:type_infer-2386:Column Sunspots has data type float</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2386:Starting statistical analysis</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2386:Finished statistical analysis</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2386:Unable to import black formatter, predictor code might be a bit ugly.</span>
</pre></div></div>
</div>
</div>
<div class="section" id="Train">
<h2>Train<a class="headerlink" href="#Train" title="Permalink to this headline">¶</a></h2>
<p>Okay, everything is ready now for our predictor to learn based on the training data we will provide.</p>
<p>Internally, lightwood cleans and reshapes the data, featurizes measurements and timestamps, and comes up with a handful of different models that will be evaluated to keep the one that produces the best forecasts.</p>
<p>Let’s train the predictor. This should take a couple of minutes, at most:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predictor</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
<span class="ansi-green-fg">INFO:dataprep_ml-2386:[Learn phase 1/8] - Statistical analysis</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2386:Starting statistical analysis</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2386:Finished statistical analysis</span>
<span class="ansi-white-fg">DEBUG:lightwood-2386: `analyze_data` runtime: 0.28 seconds</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2386:[Learn phase 2/8] - Data preprocessing</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2386:Cleaning the data</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2386:Transforming timeseries data</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Using 1 processes to reshape.</span>
<span class="ansi-white-fg">DEBUG:lightwood-2386: `preprocess` runtime: 1.16 seconds</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2386:[Learn phase 3/8] - Data splitting</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2386:Splitting the data into train/test</span>
<span class="ansi-white-fg">DEBUG:lightwood-2386: `split` runtime: 0.0 seconds</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2386:[Learn phase 4/8] - Preparing encoders</span>
<span class="ansi-white-fg">DEBUG:lightwood-2386: `prepare` runtime: 1.35 seconds</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2386:[Learn phase 5/8] - Feature generation</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2386:Featurizing the data</span>
<span class="ansi-white-fg">DEBUG:lightwood-2386: `featurize` runtime: 0.0 seconds</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2386:[Learn phase 6/8] - Mixer training</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2386:Training the mixers</span>
/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
  warnings.warn(&#34;torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.&#34;)
/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/pytorch_ranger/ranger.py:172: UserWarning: This overload of addcmul_ is deprecated:
        addcmul_(Number value, Tensor tensor1, Tensor tensor2)
Consider using one of the following signatures instead:
        addcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1420.)
  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)
<span class="ansi-green-fg">INFO:lightwood-2386:Loss of 1.0329926013946533 with learning rate 0.0001</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss of 1.1903289556503296 with learning rate 0.00014</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Found learning rate of: 0.0001</span>
/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
  warnings.warn(&#34;torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.&#34;)
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 1: 1.1034753024578094</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 2: 1.095501959323883</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 3: 1.0858559012413025</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 4: 1.0747196078300476</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 5: 1.0622954070568085</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 6: 1.048841506242752</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 7: 1.0255158841609955</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 8: 1.0098527669906616</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 9: 0.9937497973442078</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 10: 0.9772661030292511</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 11: 0.9605238139629364</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 12: 0.9436208009719849</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 13: 0.9162607491016388</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 14: 0.8990620821714401</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 15: 0.8817872852087021</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 16: 0.8645607382059097</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 17: 0.8474346101284027</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 18: 0.8305781781673431</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 19: 0.8042025417089462</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 20: 0.7881091237068176</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 21: 0.7722068727016449</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 22: 0.7565807551145554</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 23: 0.7411937415599823</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 24: 0.7263694256544113</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 25: 0.7029972970485687</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 26: 0.6888779997825623</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 27: 0.6751686930656433</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 28: 0.6619367748498917</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 29: 0.6491909772157669</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 30: 0.637048989534378</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 31: 0.6186306327581406</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 32: 0.60767962038517</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 33: 0.5971599668264389</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 34: 0.58713598549366</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 35: 0.5775429457426071</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 36: 0.5685418844223022</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 37: 0.5552376806735992</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 38: 0.5476974844932556</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 39: 0.5406321883201599</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 40: 0.5339476019144058</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 41: 0.5278284996747971</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 42: 0.5223130881786346</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 43: 0.5145178437232971</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 44: 0.510201022028923</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 45: 0.5060697197914124</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 46: 0.50221286714077</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 47: 0.4985281974077225</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 48: 0.49505120515823364</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 49: 0.48994484543800354</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 50: 0.48701275885105133</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 51: 0.4842304289340973</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 52: 0.48161080479621887</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 53: 0.4790755808353424</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 54: 0.47666411101818085</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 55: 0.47304385900497437</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 56: 0.47082482278347015</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 57: 0.46869808435440063</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 58: 0.4666435271501541</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 59: 0.464618980884552</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 60: 0.46269021928310394</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 61: 0.4597126990556717</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 62: 0.45786529779434204</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 63: 0.4560927748680115</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 64: 0.4543333649635315</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 65: 0.45258909463882446</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 66: 0.45091821253299713</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 67: 0.4484705179929733</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 68: 0.44697272777557373</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 69: 0.44543930888175964</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 70: 0.44387853145599365</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 71: 0.44231343269348145</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 72: 0.44085007905960083</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 73: 0.4386945962905884</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 74: 0.437523677945137</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 75: 0.43645091354846954</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 76: 0.43544214963912964</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 77: 0.4344274550676346</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 78: 0.4335276633501053</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 79: 0.4323144108057022</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 80: 0.43157218396663666</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 81: 0.43086080253124237</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 82: 0.43016307055950165</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 83: 0.4294184297323227</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 84: 0.42881180346012115</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 85: 0.4279477745294571</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 86: 0.4274057000875473</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 87: 0.4268777370452881</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 88: 0.4263402074575424</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 89: 0.42579421401023865</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 90: 0.4253769814968109</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 91: 0.4247869849205017</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 92: 0.42434193193912506</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 93: 0.4238846153020859</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 94: 0.42337164282798767</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 95: 0.4228121340274811</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 96: 0.4223635047674179</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 97: 0.42170239984989166</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 98: 0.42123469710350037</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 99: 0.4207599312067032</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 100: 0.4202761799097061</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 101: 0.4197620153427124</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 102: 0.41937676072120667</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 103: 0.4187953770160675</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 104: 0.4183180183172226</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 105: 0.41788506507873535</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 106: 0.417472168803215</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 107: 0.4170648753643036</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 108: 0.4167666733264923</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 109: 0.4163156747817993</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 110: 0.41593851149082184</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 111: 0.4155943840742111</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 112: 0.4152301847934723</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 113: 0.4148157387971878</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 114: 0.4145033359527588</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 115: 0.41408658027648926</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 116: 0.4137841761112213</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 117: 0.4134952276945114</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 118: 0.4131700098514557</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 119: 0.41280579566955566</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 120: 0.4125281572341919</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 121: 0.4121098667383194</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 122: 0.41173672676086426</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 123: 0.41137613356113434</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 124: 0.4110196977853775</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 125: 0.41062673926353455</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 126: 0.41032738983631134</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 127: 0.4099058359861374</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 128: 0.4095451235771179</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 129: 0.4091803729534149</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 130: 0.408763587474823</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 131: 0.4082919657230377</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 132: 0.4079209268093109</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 133: 0.4074171334505081</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 134: 0.4070437401533127</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 135: 0.40667395293712616</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 136: 0.40629446506500244</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 137: 0.40589527785778046</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 138: 0.40561071038246155</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 139: 0.4052048772573471</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 140: 0.40484729409217834</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 141: 0.40448762476444244</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 142: 0.404096320271492</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 143: 0.40366026759147644</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 144: 0.4033209830522537</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 145: 0.4028616100549698</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 146: 0.4024931639432907</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 147: 0.40213704109191895</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 148: 0.4017384201288223</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 149: 0.4013146907091141</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 150: 0.40100035071372986</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 151: 0.40055666863918304</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 152: 0.40019549429416656</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 153: 0.3998621553182602</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 154: 0.39952023327350616</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 155: 0.3991542011499405</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 156: 0.39889393746852875</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 157: 0.3985651135444641</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 158: 0.3982636034488678</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 159: 0.39793550968170166</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 160: 0.3975651413202286</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 161: 0.39716948568820953</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 162: 0.39687032997608185</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 163: 0.396462082862854</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 164: 0.39612841606140137</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 165: 0.39580969512462616</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 166: 0.3954784721136093</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 167: 0.39509347081184387</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 168: 0.394807368516922</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 169: 0.39445361495018005</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 170: 0.3941359668970108</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 171: 0.39380547404289246</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 172: 0.3934454321861267</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 173: 0.39307455718517303</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 174: 0.39280252158641815</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 175: 0.3924303203821182</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 176: 0.39212191104888916</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 177: 0.3918156921863556</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 178: 0.391501322388649</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 179: 0.391140341758728</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 180: 0.39090628921985626</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 181: 0.39064571261405945</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 182: 0.39038272202014923</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 183: 0.39010322093963623</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 184: 0.3897349387407303</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 185: 0.38938409090042114</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 186: 0.3892083317041397</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 187: 0.38904067873954773</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 188: 0.38877740502357483</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 189: 0.3885445296764374</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 190: 0.3882351815700531</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 191: 0.3878766745328903</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 192: 0.38763152062892914</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 193: 0.38736990094184875</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 194: 0.3870593160390854</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 195: 0.3867523670196533</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 196: 0.3863958716392517</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 197: 0.38602086901664734</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 198: 0.38580790162086487</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 199: 0.3856106847524643</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 200: 0.3853207975625992</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 201: 0.38502247631549835</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 202: 0.3846900463104248</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 203: 0.3842904418706894</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 204: 0.3840397745370865</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 205: 0.38381969928741455</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 206: 0.38354043662548065</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 207: 0.383292019367218</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 208: 0.3830767571926117</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 209: 0.38282108306884766</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 210: 0.3826737552881241</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 211: 0.3825233578681946</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 212: 0.3823092579841614</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 213: 0.3821367174386978</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 214: 0.3818746954202652</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 215: 0.38155296444892883</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 216: 0.3813793361186981</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 217: 0.3813055157661438</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 218: 0.3811563104391098</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 219: 0.38100071251392365</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 220: 0.38076360523700714</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 221: 0.3804292529821396</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 222: 0.3802378177642822</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 223: 0.38011954724788666</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 224: 0.3799019753932953</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 225: 0.37969571352005005</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 226: 0.37940196692943573</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 227: 0.3790878653526306</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 228: 0.3790477216243744</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 229: 0.37917323410511017</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 230: 0.37887418270111084</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 231: 0.3786562830209732</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 232: 0.37841928005218506</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 233: 0.378013551235199</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 234: 0.37777362763881683</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 235: 0.37766019999980927</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 236: 0.37750108540058136</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 237: 0.3774365037679672</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 238: 0.3771851360797882</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 239: 0.3768482059240341</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 240: 0.3767286688089371</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 241: 0.3766554594039917</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 242: 0.3764423429965973</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 243: 0.37622128427028656</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 244: 0.37601350247859955</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 245: 0.37570999562740326</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 246: 0.3755108267068863</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 247: 0.3756100535392761</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 248: 0.3755151629447937</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 249: 0.37535738945007324</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 250: 0.3750864118337631</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 251: 0.3748052716255188</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 252: 0.374685600399971</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 253: 0.3747425824403763</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 254: 0.3746403753757477</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 255: 0.37452957034111023</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 256: 0.3743480443954468</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 257: 0.3740883320569992</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 258: 0.37391504645347595</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 259: 0.37386322021484375</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 260: 0.3737812787294388</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 261: 0.3735518157482147</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 262: 0.373261496424675</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 263: 0.37293653190135956</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 264: 0.3727949857711792</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 265: 0.37271177768707275</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 266: 0.3725355565547943</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 267: 0.3723742365837097</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 268: 0.37211884558200836</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 269: 0.37185609340667725</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 270: 0.3717389404773712</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 271: 0.371671661734581</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 272: 0.37156540155410767</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 273: 0.37144364416599274</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 274: 0.3712071627378464</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 275: 0.37085430324077606</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 276: 0.37077565491199493</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 277: 0.370758980512619</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 278: 0.3706369698047638</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 279: 0.3705045133829117</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 280: 0.3702728897333145</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 281: 0.36993730068206787</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 282: 0.36982929706573486</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 283: 0.3697909563779831</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 284: 0.3696880042552948</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 285: 0.3695372939109802</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 286: 0.3693208545446396</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 287: 0.36899493634700775</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 288: 0.36897672712802887</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 289: 0.3689476251602173</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 290: 0.3687288463115692</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 291: 0.36871758103370667</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 292: 0.3685424029827118</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 293: 0.36824989318847656</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 294: 0.3681942820549011</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 295: 0.3682515323162079</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 296: 0.3681076467037201</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 297: 0.3681086599826813</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 298: 0.3680892139673233</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 299: 0.3677977919578552</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 300: 0.3678208738565445</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 301: 0.3680317848920822</span>
/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
  warnings.warn(&#34;torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.&#34;)
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 1: 0.2805658280849457</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 2: 0.28063051267103717</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 3: 0.28062370961362665</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 4: 0.2808729789473794</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 5: 0.2864390801299702</span>
<span class="ansi-white-fg">DEBUG:lightwood-2386: `fit_mixer` runtime: 18.62 seconds</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Started fitting AutoSKTime forecaster for array prediction</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Starting trial with hyperparameters: {&#39;class&#39;: &#39;croston.Croston&#39;}</span>
<span class="ansi-yellow-fg">WARNING:lightwood-2386:This mixer does not output probability estimates</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Trial got error: 0.19796658477664864</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Starting trial with hyperparameters: {&#39;class&#39;: &#39;trend.STLForecaster&#39;}</span>
<span class="ansi-yellow-fg">WARNING:lightwood-2386:This mixer does not output probability estimates</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Trial got error: 0.5245438066022906</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Starting trial with hyperparameters: {&#39;class&#39;: &#39;trend.PolynomialTrendForecaster&#39;}</span>
<span class="ansi-yellow-fg">WARNING:lightwood-2386:This mixer does not output probability estimates</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Trial got error: 0.683102101870188</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Starting trial with hyperparameters: {&#39;class&#39;: &#39;theta.ThetaForecaster&#39;}</span>
<span class="ansi-white-fg">DEBUG:lightwood-2386:Multiplicative seasonality is not appropriate for zero and negative values</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Trial got error: inf</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Selected best model: croston.Croston</span>
<span class="ansi-white-fg">DEBUG:lightwood-2386: `fit_mixer` runtime: 0.25 seconds</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Started fitting AutoETS forecaster for array prediction</span>
<span class="ansi-white-fg">DEBUG:lightwood-2386: `fit_mixer` runtime: 0.09 seconds</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Started fitting AutoARIMA forecaster for array prediction</span>
/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/scipy/optimize/_numdiff.py:576: RuntimeWarning: invalid value encountered in subtract
  df = fun(x) - f0
/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/statsforecast/arima.py:884: UserWarning: possible convergence problem: minimize gave code 2]
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/statsforecast/arima.py:884: UserWarning: possible convergence problem: minimize gave code 2]
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/statsforecast/arima.py:884: UserWarning: possible convergence problem: minimize gave code 2]
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/statsforecast/arima.py:884: UserWarning: possible convergence problem: minimize gave code 2]
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/statsforecast/arima.py:884: UserWarning: possible convergence problem: minimize gave code 2]
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/statsforecast/arima.py:884: UserWarning: possible convergence problem: minimize gave code 2]
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/statsforecast/arima.py:884: UserWarning: possible convergence problem: minimize gave code 2]
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/statsforecast/arima.py:884: UserWarning: possible convergence problem: minimize gave code 2]
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/statsforecast/arima.py:884: UserWarning: possible convergence problem: minimize gave code 2]
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/statsforecast/arima.py:884: UserWarning: possible convergence problem: minimize gave code 2]
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/statsforecast/arima.py:884: UserWarning: possible convergence problem: minimize gave code 2]
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/statsforecast/arima.py:884: UserWarning: possible convergence problem: minimize gave code 2]
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/statsforecast/arima.py:884: UserWarning: possible convergence problem: minimize gave code 2]
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/statsforecast/arima.py:884: UserWarning: possible convergence problem: minimize gave code 2]
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/statsforecast/arima.py:884: UserWarning: possible convergence problem: minimize gave code 2]
  warnings.warn(
<span class="ansi-white-fg">DEBUG:lightwood-2386: `fit_mixer` runtime: 17.53 seconds</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2386:Ensembling the mixer</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Mixer: NeuralTs got accuracy: 0.875</span>
<span class="ansi-yellow-fg">WARNING:lightwood-2386:This mixer does not output probability estimates</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Mixer: SkTime got accuracy: 0.956</span>
<span class="ansi-yellow-fg">WARNING:lightwood-2386:This mixer does not output probability estimates</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Mixer: ETSMixer got accuracy: 0.934</span>
<span class="ansi-yellow-fg">WARNING:lightwood-2386:This mixer does not output probability estimates</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Mixer: ARIMAMixer got accuracy: 0.951</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Picked best mixer: SkTime</span>
<span class="ansi-white-fg">DEBUG:lightwood-2386: `fit` runtime: 37.8 seconds</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2386:[Learn phase 7/8] - Ensemble analysis</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2386:Analyzing the ensemble of mixers</span>
<span class="ansi-yellow-fg">WARNING:lightwood-2386:This mixer does not output probability estimates</span>
<span class="ansi-green-fg">INFO:lightwood-2386:The block ICP is now running its analyze() method</span>
<span class="ansi-green-fg">INFO:lightwood-2386:The block ConfStats is now running its analyze() method</span>
<span class="ansi-green-fg">INFO:lightwood-2386:The block AccStats is now running its analyze() method</span>
<span class="ansi-green-fg">INFO:lightwood-2386:The block PermutationFeatureImportance is now running its analyze() method</span>
<span class="ansi-yellow-fg">WARNING:lightwood-2386:Block &#39;PermutationFeatureImportance&#39; does not support time series nor text encoding, skipping...</span>
<span class="ansi-white-fg">DEBUG:lightwood-2386: `analyze_ensemble` runtime: 0.02 seconds</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2386:[Learn phase 8/8] - Adjustment on validation requested</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2386:Updating the mixers</span>
/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
  warnings.warn(&#34;torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.&#34;)
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 1: 0.2871488655606906</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 2: 0.2868730003635089</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 3: 0.28785818815231323</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 4: 0.28558123111724854</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 5: 0.28589582939942676</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Loss @ epoch 6: 0.28774098803599674</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Started fitting AutoSKTime forecaster for array prediction</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Selected best model: croston.Croston</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Started fitting AutoETS forecaster for array prediction</span>
<span class="ansi-green-fg">INFO:lightwood-2386:Started fitting AutoARIMA forecaster for array prediction</span>
/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/statsforecast/arima.py:884: UserWarning: possible convergence problem: minimize gave code 2]
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/statsforecast/arima.py:884: UserWarning: possible convergence problem: minimize gave code 2]
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/statsforecast/arima.py:884: UserWarning: possible convergence problem: minimize gave code 2]
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/statsforecast/arima.py:884: UserWarning: possible convergence problem: minimize gave code 2]
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/statsforecast/arima.py:884: UserWarning: possible convergence problem: minimize gave code 2]
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/statsforecast/arima.py:884: UserWarning: possible convergence problem: minimize gave code 2]
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/statsforecast/arima.py:884: UserWarning: possible convergence problem: minimize gave code 2]
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/statsforecast/arima.py:884: UserWarning: possible convergence problem: minimize gave code 2]
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/statsforecast/arima.py:884: UserWarning: possible convergence problem: minimize gave code 2]
  warnings.warn(
<span class="ansi-white-fg">DEBUG:lightwood-2386: `adjust` runtime: 11.89 seconds</span>
<span class="ansi-white-fg">DEBUG:lightwood-2386: `learn` runtime: 52.55 seconds</span>
</pre></div></div>
</div>
</div>
<div class="section" id="Predict">
<h2>Predict<a class="headerlink" href="#Predict" title="Permalink to this headline">¶</a></h2>
<p>Once the predictor has trained, we can use it to generate 6-month forecasts for each of the test set data points:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">forecasts</span> <span class="o">=</span> <span class="n">predictor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
<span class="ansi-green-fg">INFO:dataprep_ml-2386:[Predict phase 1/4] - Data preprocessing</span>
/tmp/cd9ca2ad4147a9be9bc7c5b62776cebf573d2a45d9c1f0eb1678999823489218.py:566: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data[col] = [None] * len(data)
<span class="ansi-green-fg">INFO:dataprep_ml-2386:Cleaning the data</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2386:Transforming timeseries data</span>
<span class="ansi-white-fg">DEBUG:lightwood-2386: `preprocess` runtime: 0.12 seconds</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2386:[Predict phase 2/4] - Feature generation</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2386:Featurizing the data</span>
<span class="ansi-white-fg">DEBUG:lightwood-2386: `featurize` runtime: 0.0 seconds</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2386:[Predict phase 3/4] - Calling ensemble</span>
<span class="ansi-yellow-fg">WARNING:lightwood-2386:This mixer does not output probability estimates</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2386:[Predict phase 4/4] - Analyzing output</span>
/home/runner/work/lightwood/lightwood/lightwood/helpers/ts.py:122: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df[f&#39;order_{col}&#39;].iloc[idx] = timestamps
<span class="ansi-green-fg">INFO:lightwood-2386:The block ICP is now running its explain() method</span>
<span class="ansi-green-fg">INFO:lightwood-2386:The block ConfStats is now running its explain() method</span>
<span class="ansi-green-fg">INFO:lightwood-2386:ConfStats.explain() has not been implemented, no modifications will be done to the data insights.</span>
<span class="ansi-green-fg">INFO:lightwood-2386:The block AccStats is now running its explain() method</span>
<span class="ansi-green-fg">INFO:lightwood-2386:AccStats.explain() has not been implemented, no modifications will be done to the data insights.</span>
<span class="ansi-green-fg">INFO:lightwood-2386:The block PermutationFeatureImportance is now running its explain() method</span>
<span class="ansi-green-fg">INFO:lightwood-2386:PermutationFeatureImportance.explain() has not been implemented, no modifications will be done to the data insights.</span>
<span class="ansi-white-fg">DEBUG:lightwood-2386: `predict` runtime: 0.56 seconds</span>
</pre></div></div>
</div>
<p>Let’s check how a single row might look:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">forecasts</span><span class="o">.</span><span class="n">iloc</span><span class="p">[[</span><span class="mi">10</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>original_index</th>
      <th>prediction</th>
      <th>order_Month</th>
      <th>confidence</th>
      <th>lower</th>
      <th>upper</th>
      <th>anomaly</th>
      <th>prediction_sum</th>
      <th>lower_sum</th>
      <th>upper_sum</th>
      <th>confidence_mean</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>10</th>
      <td>10</td>
      <td>[139.64101541907135, 139.64101541907135, 139.6...</td>
      <td>[-272332800.0, -269654400.0, -266976000.0, -26...</td>
      <td>[0.99, 0.99, 0.99, 0.99, 0.99, 0.99]</td>
      <td>[138.49473921001066, 137.38729162813206, 132.5...</td>
      <td>[140.78729162813204, 141.89473921001064, 146.6...</td>
      <td>True</td>
      <td>837.846093</td>
      <td>120.087292</td>
      <td>159.194739</td>
      <td>0.99</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>You’ll note that the point <code class="docutils literal notranslate"><span class="pre">prediction</span></code> has associated <code class="docutils literal notranslate"><span class="pre">lower</span></code> and <code class="docutils literal notranslate"><span class="pre">upper</span></code> bounds that are a function of the estimated <code class="docutils literal notranslate"><span class="pre">confidence</span></code> the model has on its own output. Apart from this, <code class="docutils literal notranslate"><span class="pre">order_Month</span></code> yields the timestamps of each prediction, the <code class="docutils literal notranslate"><span class="pre">anomaly</span></code> tag will let you know if the observed value falls outside of the predicted region.</p>
</div>
<div class="section" id="Visualizing-a-forecast">
<h2>Visualizing a forecast<a class="headerlink" href="#Visualizing-a-forecast" title="Permalink to this headline">¶</a></h2>
<p>Okay, time series are much easier to appreciate through plots. Let’s make one:</p>
<p>NOTE: We will use <code class="docutils literal notranslate"><span class="pre">matplotlib</span></code> to generate a simple plot of these forecasts. If you want to run this notebook locally, you will need to <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">matplotlib</span></code> for the following code to work.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="kc">None</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">forecasts</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span> <span class="o">+</span> <span class="n">forecasts</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;prediction&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;purple&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;point prediction&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="kc">None</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">forecasts</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span> <span class="o">+</span> <span class="n">forecasts</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;lower&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="kc">None</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">forecasts</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span> <span class="o">+</span> <span class="n">forecasts</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;upper&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;timestep&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;# sunspots&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Forecasted amount of sunspots for the next semester&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_tutorial_time_series_tutorial_time_series_17_0.png" src="../../_images/tutorials_tutorial_time_series_tutorial_time_series_17_0.png" />
</div>
</div>
</div>
<div class="section" id="Conclusion">
<h2>Conclusion<a class="headerlink" href="#Conclusion" title="Permalink to this headline">¶</a></h2>
<p>In this tutorial, we have gone through how you can train a machine learning model with Lightwood to produce forecasts for a univariate time series task.</p>
<p>There are additional parameters to further customize your timeseries settings and/or prediction insights, so be sure to check the rest of the documentation.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2017-2023, MindsDB.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>
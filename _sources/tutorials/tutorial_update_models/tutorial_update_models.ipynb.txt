{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this tutorial, we will go through an example to update a preexisting model. This might be useful when you come across additional data that you would want to consider, without having to train a model from scratch.\n",
    "\n",
    "The main abstraction that Lightwood offers for this is the `BaseMixer.partial_fit()` method. To call it, you need to pass new training data and a held-out dev subset for internal mixer usage (e.g. early stopping). If you are using an aggregate ensemble, it's likely you will want to do this for every single mixer. The convienient `PredictorInterface.adjust()` does this automatically for you.\n",
    "\n",
    "\n",
    "# Initial model training\n",
    "\n",
    "First, let's train a Lightwood predictor for the `concrete strength` dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-23T16:19:23.819768Z",
     "iopub.status.busy": "2023-06-23T16:19:23.819510Z",
     "iopub.status.idle": "2023-06-23T16:19:30.046179Z",
     "shell.execute_reply": "2023-06-23T16:19:30.045383Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/runner/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "\u001b[32mINFO:lightwood-2246:No torchvision detected, image helpers not supported.\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2246:No torchvision/pillow detected, image encoder not supported\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from lightwood.api.high_level import ProblemDefinition, json_ai_from_problem, predictor_from_json_ai\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-23T16:19:30.049956Z",
     "iopub.status.busy": "2023-06-23T16:19:30.049421Z",
     "iopub.status.idle": "2023-06-23T16:19:30.295637Z",
     "shell.execute_reply": "2023-06-23T16:19:30.294818Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataframe shape: (103, 10)\n",
      "Update dataframe shape: (721, 10)\n",
      "Test dataframe shape: (206, 10)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/mindsdb/lightwood/staging/tests/data/concrete_strength.csv')\n",
    "\n",
    "df = df.sample(frac=1, random_state=1)\n",
    "train_df = df[:int(0.1*len(df))]\n",
    "update_df = df[int(0.1*len(df)):int(0.8*len(df))]\n",
    "test_df = df[int(0.8*len(df)):]\n",
    "\n",
    "print(f'Train dataframe shape: {train_df.shape}')\n",
    "print(f'Update dataframe shape: {update_df.shape}')\n",
    "print(f'Test dataframe shape: {test_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have three different data splits.\n",
    "\n",
    "We will use the `training` split for the initial model training. As you can see, it's only a 20% of the total data we have. The `update` split will be used as training data to adjust/update our model. Finally, the held out `test` set will give us a rough idea of the impact our updating procedure has on the model's predictive capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-23T16:19:30.299522Z",
     "iopub.status.busy": "2023-06-23T16:19:30.299123Z",
     "iopub.status.idle": "2023-06-23T16:19:31.453599Z",
     "shell.execute_reply": "2023-06-23T16:19:31.453037Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:type_infer-2246:Analyzing a sample of 979\u001b[0m\n",
      "\u001b[32mINFO:type_infer-2246:from a total population of 1030, this is equivalent to 95.0% of your data.\u001b[0m\n",
      "\u001b[32mINFO:type_infer-2246:Infering type for: id\u001b[0m\n",
      "\u001b[32mINFO:type_infer-2246:Column id has data type integer\u001b[0m\n",
      "\u001b[32mINFO:type_infer-2246:Infering type for: cement\u001b[0m\n",
      "\u001b[32mINFO:type_infer-2246:Column cement has data type float\u001b[0m\n",
      "\u001b[32mINFO:type_infer-2246:Infering type for: slag\u001b[0m\n",
      "\u001b[32mINFO:type_infer-2246:Column slag has data type float\u001b[0m\n",
      "\u001b[32mINFO:type_infer-2246:Infering type for: flyAsh\u001b[0m\n",
      "\u001b[32mINFO:type_infer-2246:Column flyAsh has data type float\u001b[0m\n",
      "\u001b[32mINFO:type_infer-2246:Infering type for: water\u001b[0m\n",
      "\u001b[32mINFO:type_infer-2246:Column water has data type float\u001b[0m\n",
      "\u001b[32mINFO:type_infer-2246:Infering type for: superPlasticizer\u001b[0m\n",
      "\u001b[32mINFO:type_infer-2246:Column superPlasticizer has data type float\u001b[0m\n",
      "\u001b[32mINFO:type_infer-2246:Infering type for: coarseAggregate\u001b[0m\n",
      "\u001b[32mINFO:type_infer-2246:Column coarseAggregate has data type float\u001b[0m\n",
      "\u001b[32mINFO:type_infer-2246:Infering type for: fineAggregate\u001b[0m\n",
      "\u001b[32mINFO:type_infer-2246:Column fineAggregate has data type float\u001b[0m\n",
      "\u001b[32mINFO:type_infer-2246:Infering type for: age\u001b[0m\n",
      "\u001b[32mINFO:type_infer-2246:Column age has data type integer\u001b[0m\n",
      "\u001b[32mINFO:type_infer-2246:Infering type for: concrete_strength\u001b[0m\n",
      "\u001b[32mINFO:type_infer-2246:Column concrete_strength has data type float\u001b[0m\n",
      "\u001b[32mINFO:dataprep_ml-2246:Starting statistical analysis\u001b[0m\n",
      "\u001b[32mINFO:dataprep_ml-2246:Finished statistical analysis\u001b[0m\n",
      "\u001b[32mINFO:dataprep_ml-2246:[Learn phase 1/8] - Statistical analysis\u001b[0m\n",
      "\u001b[32mINFO:dataprep_ml-2246:Starting statistical analysis\u001b[0m\n",
      "\u001b[32mINFO:dataprep_ml-2246:Finished statistical analysis\u001b[0m\n",
      "\u001b[37mDEBUG:lightwood-2246: `analyze_data` runtime: 0.02 seconds\u001b[0m\n",
      "\u001b[32mINFO:dataprep_ml-2246:[Learn phase 2/8] - Data preprocessing\u001b[0m\n",
      "\u001b[32mINFO:dataprep_ml-2246:Cleaning the data\u001b[0m\n",
      "\u001b[37mDEBUG:lightwood-2246: `preprocess` runtime: 0.01 seconds\u001b[0m\n",
      "\u001b[32mINFO:dataprep_ml-2246:[Learn phase 3/8] - Data splitting\u001b[0m\n",
      "\u001b[32mINFO:dataprep_ml-2246:Splitting the data into train/test\u001b[0m\n",
      "\u001b[37mDEBUG:lightwood-2246: `split` runtime: 0.0 seconds\u001b[0m\n",
      "\u001b[32mINFO:dataprep_ml-2246:[Learn phase 4/8] - Preparing encoders\u001b[0m\n",
      "\u001b[37mDEBUG:dataprep_ml-2246:Preparing sequentially...\u001b[0m\n",
      "\u001b[37mDEBUG:dataprep_ml-2246:Preparing encoder for id...\u001b[0m\n",
      "\u001b[37mDEBUG:dataprep_ml-2246:Preparing encoder for cement...\u001b[0m\n",
      "\u001b[37mDEBUG:dataprep_ml-2246:Preparing encoder for slag...\u001b[0m\n",
      "\u001b[37mDEBUG:dataprep_ml-2246:Preparing encoder for flyAsh...\u001b[0m\n",
      "\u001b[37mDEBUG:dataprep_ml-2246:Preparing encoder for water...\u001b[0m\n",
      "\u001b[37mDEBUG:dataprep_ml-2246:Preparing encoder for superPlasticizer...\u001b[0m\n",
      "\u001b[37mDEBUG:dataprep_ml-2246:Preparing encoder for coarseAggregate...\u001b[0m\n",
      "\u001b[37mDEBUG:dataprep_ml-2246:Preparing encoder for fineAggregate...\u001b[0m\n",
      "\u001b[37mDEBUG:dataprep_ml-2246:Preparing encoder for age...\u001b[0m\n",
      "\u001b[37mDEBUG:lightwood-2246: `prepare` runtime: 0.01 seconds\u001b[0m\n",
      "\u001b[32mINFO:dataprep_ml-2246:[Learn phase 5/8] - Feature generation\u001b[0m\n",
      "\u001b[32mINFO:dataprep_ml-2246:Featurizing the data\u001b[0m\n",
      "\u001b[37mDEBUG:lightwood-2246: `featurize` runtime: 0.07 seconds\u001b[0m\n",
      "\u001b[32mINFO:dataprep_ml-2246:[Learn phase 6/8] - Mixer training\u001b[0m\n",
      "\u001b[32mINFO:dataprep_ml-2246:Training the mixers\u001b[0m\n",
      "/opt/hostedtoolcache/Python/3.9.17/x64/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:120: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "/opt/hostedtoolcache/Python/3.9.17/x64/lib/python3.9/site-packages/pytorch_ranger/ranger.py:172: UserWarning: This overload of addcmul_ is deprecated:\n",
      "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
      "Consider using one of the following signatures instead:\n",
      "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1485.)\n",
      "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
      "\u001b[32mINFO:lightwood-2246:Loss of 39.99637413024902 with learning rate 0.0001\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2246:Loss of 21.826460480690002 with learning rate 0.0005\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2246:Loss of 15.12899625301361 with learning rate 0.001\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2246:Loss of 15.062753677368164 with learning rate 0.002\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2246:Loss of 26.490498542785645 with learning rate 0.003\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2246:Loss of 33.65720558166504 with learning rate 0.005\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2246:Loss of 303.607186794281 with learning rate 0.01\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2246:Loss of nan with learning rate 0.05\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2246:Found learning rate of: 0.002\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2246:Loss @ epoch 1: 0.11838733404874802\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2246:Loss @ epoch 2: 0.4641949534416199\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2246:Loss @ epoch 3: 0.3976145088672638\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2246:Loss @ epoch 4: 0.3706841766834259\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2246:Loss @ epoch 5: 0.2367912083864212\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2246:Loss @ epoch 6: 0.22560922801494598\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2246:Loss @ epoch 7: 0.12089194357395172\u001b[0m\n",
      "\u001b[37mDEBUG:lightwood-2246: `fit_mixer` runtime: 0.2 seconds\u001b[0m\n",
      "\u001b[32mINFO:dataprep_ml-2246:Ensembling the mixer\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2246:Mixer: Neural got accuracy: 0.238\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2246:Picked best mixer: Neural\u001b[0m\n",
      "\u001b[37mDEBUG:lightwood-2246: `fit` runtime: 0.2 seconds\u001b[0m\n",
      "\u001b[32mINFO:dataprep_ml-2246:[Learn phase 7/8] - Ensemble analysis\u001b[0m\n",
      "\u001b[32mINFO:dataprep_ml-2246:Analyzing the ensemble of mixers\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2246:The block ICP is now running its analyze() method\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2246:The block ConfStats is now running its analyze() method\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2246:The block AccStats is now running its analyze() method\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2246:The block PermutationFeatureImportance is now running its analyze() method\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2246:[PFI] Using a random sample (1000 rows out of 10).\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2246:[PFI] Set to consider first 10 columns out of 9: ['id', 'cement', 'slag', 'flyAsh', 'water', 'superPlasticizer', 'coarseAggregate', 'fineAggregate', 'age'].\u001b[0m\n",
      "\u001b[37mDEBUG:lightwood-2246: `analyze_ensemble` runtime: 0.2 seconds\u001b[0m\n",
      "\u001b[32mINFO:dataprep_ml-2246:[Learn phase 8/8] - Adjustment on validation requested\u001b[0m\n",
      "\u001b[32mINFO:dataprep_ml-2246:Updating the mixers\u001b[0m\n",
      "/opt/hostedtoolcache/Python/3.9.17/x64/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:120: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "\u001b[32mINFO:lightwood-2246:Loss @ epoch 1: 0.1678172399600347\u001b[0m\n",
      "\u001b[37mDEBUG:lightwood-2246: `adjust` runtime: 0.03 seconds\u001b[0m\n",
      "\u001b[37mDEBUG:lightwood-2246: `learn` runtime: 0.56 seconds\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Define predictive task and predictor\n",
    "target = 'concrete_strength'\n",
    "pdef = ProblemDefinition.from_dict({'target': target, 'time_aim': 200})\n",
    "jai = json_ai_from_problem(df, pdef)\n",
    "\n",
    "# We will keep the architecture simple: a single neural mixer, and a `BestOf` ensemble:\n",
    "jai.model = {\n",
    "    \"module\": \"BestOf\",\n",
    "    \"args\": {\n",
    "        \"args\": \"$pred_args\",\n",
    "        \"accuracy_functions\": \"$accuracy_functions\",\n",
    "        \"submodels\": [{\n",
    "            \"module\": \"Neural\",\n",
    "            \"args\": {\n",
    "                \"fit_on_dev\": False,\n",
    "                \"stop_after\": \"$problem_definition.seconds_per_mixer\",\n",
    "                \"search_hyperparameters\": False,\n",
    "            }\n",
    "        }]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Build and train the predictor\n",
    "predictor = predictor_from_json_ai(jai)\n",
    "predictor.learn(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-23T16:19:31.456470Z",
     "iopub.status.busy": "2023-06-23T16:19:31.456070Z",
     "iopub.status.idle": "2023-06-23T16:19:31.622637Z",
     "shell.execute_reply": "2023-06-23T16:19:31.621929Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:dataprep_ml-2246:[Predict phase 1/4] - Data preprocessing\u001b[0m\n",
      "\u001b[32mINFO:dataprep_ml-2246:Cleaning the data\u001b[0m\n",
      "\u001b[37mDEBUG:lightwood-2246: `preprocess` runtime: 0.01 seconds\u001b[0m\n",
      "\u001b[32mINFO:dataprep_ml-2246:[Predict phase 2/4] - Feature generation\u001b[0m\n",
      "\u001b[32mINFO:dataprep_ml-2246:Featurizing the data\u001b[0m\n",
      "\u001b[37mDEBUG:lightwood-2246: `featurize` runtime: 0.03 seconds\u001b[0m\n",
      "\u001b[32mINFO:dataprep_ml-2246:[Predict phase 3/4] - Calling ensemble\u001b[0m\n",
      "\u001b[32mINFO:dataprep_ml-2246:[Predict phase 4/4] - Analyzing output\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2246:The block ICP is now running its explain() method\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2246:The block ConfStats is now running its explain() method\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2246:ConfStats.explain() has not been implemented, no modifications will be done to the data insights.\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2246:The block AccStats is now running its explain() method\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2246:AccStats.explain() has not been implemented, no modifications will be done to the data insights.\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2246:The block PermutationFeatureImportance is now running its explain() method\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2246:PermutationFeatureImportance.explain() has not been implemented, no modifications will be done to the data insights.\u001b[0m\n",
      "\u001b[37mDEBUG:lightwood-2246: `predict` runtime: 0.15 seconds\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_index</th>\n",
       "      <th>prediction</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>40.909611</td>\n",
       "      <td>0.9991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>87.398061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>19.146818</td>\n",
       "      <td>0.9991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.635269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>22.482300</td>\n",
       "      <td>0.9991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>68.970750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>19.593750</td>\n",
       "      <td>0.9991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.082201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>31.724546</td>\n",
       "      <td>0.9991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>78.212997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>201</td>\n",
       "      <td>50.553097</td>\n",
       "      <td>0.9991</td>\n",
       "      <td>4.064646</td>\n",
       "      <td>97.041547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>202</td>\n",
       "      <td>48.580425</td>\n",
       "      <td>0.9991</td>\n",
       "      <td>2.091975</td>\n",
       "      <td>95.068876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>203</td>\n",
       "      <td>30.114187</td>\n",
       "      <td>0.9991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>76.602638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>204</td>\n",
       "      <td>25.675985</td>\n",
       "      <td>0.9991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>72.164436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>205</td>\n",
       "      <td>41.231647</td>\n",
       "      <td>0.9991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>87.720098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>206 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     original_index  prediction confidence     lower      upper\n",
       "0                 0   40.909611     0.9991  0.000000  87.398061\n",
       "1                 1   19.146818     0.9991  0.000000  65.635269\n",
       "2                 2   22.482300     0.9991  0.000000  68.970750\n",
       "3                 3   19.593750     0.9991  0.000000  66.082201\n",
       "4                 4   31.724546     0.9991  0.000000  78.212997\n",
       "..              ...         ...        ...       ...        ...\n",
       "201             201   50.553097     0.9991  4.064646  97.041547\n",
       "202             202   48.580425     0.9991  2.091975  95.068876\n",
       "203             203   30.114187     0.9991  0.000000  76.602638\n",
       "204             204   25.675985     0.9991  0.000000  72.164436\n",
       "205             205   41.231647     0.9991  0.000000  87.720098\n",
       "\n",
       "[206 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and get predictions for the held out test set\n",
    "predictions = predictor.predict(test_df)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating the predictor\n",
    "\n",
    "For this, we have two options:\n",
    "\n",
    "### `BaseMixer.partial_fit()`\n",
    "\n",
    "Updates a single mixer. You need to pass the new data wrapped in `EncodedDs` objects.\n",
    "\n",
    "**Arguments:** \n",
    "* `train_data: EncodedDs`\n",
    "* `dev_data: EncodedDs`\n",
    "* `adjust_args: Optional[dict]` - This will contain any arguments needed by the mixer to adjust new data.\n",
    "\n",
    "If the mixer does not need a `dev_data` partition, pass a dummy:\n",
    "\n",
    "```\n",
    "dev_data = EncodedDs(predictor.encoders, pd.DataFrame(), predictor.target)\n",
    "```\n",
    "\n",
    "### `PredictorInterface.adjust()`\n",
    "\n",
    "Updates all mixers inside the predictor by calling their respective `partial_fit()` methods. Any `adjust_args` will be transparently passed as well.\n",
    "\n",
    "**Arguments:**\n",
    "\n",
    "* `new_data: pd.DataFrame`\n",
    "* `old_data: Optional[pd.DataFrame]`\n",
    "* `adjust_args: Optional[dict]`\n",
    "\n",
    "Let's `adjust` our predictor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-23T16:19:31.626256Z",
     "iopub.status.busy": "2023-06-23T16:19:31.626028Z",
     "iopub.status.idle": "2023-06-23T16:19:31.729933Z",
     "shell.execute_reply": "2023-06-23T16:19:31.729304Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:dataprep_ml-2246:Cleaning the data\u001b[0m\n",
      "\u001b[37mDEBUG:lightwood-2246: `preprocess` runtime: 0.02 seconds\u001b[0m\n",
      "\u001b[32mINFO:dataprep_ml-2246:Cleaning the data\u001b[0m\n",
      "\u001b[37mDEBUG:lightwood-2246: `preprocess` runtime: 0.01 seconds\u001b[0m\n",
      "\u001b[32mINFO:dataprep_ml-2246:Updating the mixers\u001b[0m\n",
      "/opt/hostedtoolcache/Python/3.9.17/x64/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:120: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "\u001b[32mINFO:lightwood-2246:Loss @ epoch 1: 0.10915954907735188\u001b[0m\n",
      "\u001b[37mDEBUG:lightwood-2246: `adjust` runtime: 0.1 seconds\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "predictor.adjust(update_df, train_df)  # data to adjust and original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-23T16:19:31.733057Z",
     "iopub.status.busy": "2023-06-23T16:19:31.732807Z",
     "iopub.status.idle": "2023-06-23T16:19:31.905951Z",
     "shell.execute_reply": "2023-06-23T16:19:31.905340Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:dataprep_ml-2246:[Predict phase 1/4] - Data preprocessing\u001b[0m\n",
      "\u001b[32mINFO:dataprep_ml-2246:Cleaning the data\u001b[0m\n",
      "\u001b[37mDEBUG:lightwood-2246: `preprocess` runtime: 0.01 seconds\u001b[0m\n",
      "\u001b[32mINFO:dataprep_ml-2246:[Predict phase 2/4] - Feature generation\u001b[0m\n",
      "\u001b[32mINFO:dataprep_ml-2246:Featurizing the data\u001b[0m\n",
      "\u001b[37mDEBUG:lightwood-2246: `featurize` runtime: 0.03 seconds\u001b[0m\n",
      "\u001b[32mINFO:dataprep_ml-2246:[Predict phase 3/4] - Calling ensemble\u001b[0m\n",
      "\u001b[32mINFO:dataprep_ml-2246:[Predict phase 4/4] - Analyzing output\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2246:The block ICP is now running its explain() method\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2246:The block ConfStats is now running its explain() method\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2246:ConfStats.explain() has not been implemented, no modifications will be done to the data insights.\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2246:The block AccStats is now running its explain() method\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2246:AccStats.explain() has not been implemented, no modifications will be done to the data insights.\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2246:The block PermutationFeatureImportance is now running its explain() method\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2246:PermutationFeatureImportance.explain() has not been implemented, no modifications will be done to the data insights.\u001b[0m\n",
      "\u001b[37mDEBUG:lightwood-2246: `predict` runtime: 0.16 seconds\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_index</th>\n",
       "      <th>prediction</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>43.645531</td>\n",
       "      <td>0.9991</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>90.133981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>26.964922</td>\n",
       "      <td>0.9991</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>73.453373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>24.151918</td>\n",
       "      <td>0.9991</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>70.640369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>20.815779</td>\n",
       "      <td>0.9991</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>67.304229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>34.987530</td>\n",
       "      <td>0.9991</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>81.475980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>201</td>\n",
       "      <td>52.630001</td>\n",
       "      <td>0.9991</td>\n",
       "      <td>6.14155</td>\n",
       "      <td>99.118452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>202</td>\n",
       "      <td>39.175217</td>\n",
       "      <td>0.9991</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>85.663667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>203</td>\n",
       "      <td>33.047451</td>\n",
       "      <td>0.9991</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>79.535902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>204</td>\n",
       "      <td>28.659145</td>\n",
       "      <td>0.9991</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>75.147596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>205</td>\n",
       "      <td>34.264580</td>\n",
       "      <td>0.9991</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>80.753030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>206 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     original_index  prediction confidence    lower      upper\n",
       "0                 0   43.645531     0.9991  0.00000  90.133981\n",
       "1                 1   26.964922     0.9991  0.00000  73.453373\n",
       "2                 2   24.151918     0.9991  0.00000  70.640369\n",
       "3                 3   20.815779     0.9991  0.00000  67.304229\n",
       "4                 4   34.987530     0.9991  0.00000  81.475980\n",
       "..              ...         ...        ...      ...        ...\n",
       "201             201   52.630001     0.9991  6.14155  99.118452\n",
       "202             202   39.175217     0.9991  0.00000  85.663667\n",
       "203             203   33.047451     0.9991  0.00000  79.535902\n",
       "204             204   28.659145     0.9991  0.00000  75.147596\n",
       "205             205   34.264580     0.9991  0.00000  80.753030\n",
       "\n",
       "[206 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_predictions = predictor.predict(test_df)\n",
    "new_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Our predictor was updated, and new predictions are looking good. Let's compare the old and new accuracies to complete the experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-23T16:19:31.909198Z",
     "iopub.status.busy": "2023-06-23T16:19:31.908727Z",
     "iopub.status.idle": "2023-06-23T16:19:31.914858Z",
     "shell.execute_reply": "2023-06-23T16:19:31.914209Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old Accuracy: 0.233\n",
      "New Accuracy: 0.428\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "\n",
    "old_acc = r2_score(test_df['concrete_strength'], predictions['prediction'])\n",
    "new_acc = r2_score(test_df['concrete_strength'], new_predictions['prediction'])\n",
    "\n",
    "print(f'Old Accuracy: {round(old_acc, 3)}\\nNew Accuracy: {round(new_acc, 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We have gone through a simple example of how Lightwood predictors can leverage newly acquired data to improve their predictions. The interface for doing so is fairly simple, requiring only some new data and a single call to update.\n",
    "\n",
    "You can further customize the logic for updating your mixers by modifying the `partial_fit()` methods in them."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
